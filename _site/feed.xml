<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2020-05-08T19:08:33-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Zain Rizvi‚Äôs blog</title><subtitle>Zain Rizvi's blog. Sharing interesting things I'm learning about Software, Psychology, Self Improvment, and Business</subtitle><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><entry><title type="html">Remembering what you read: Zettelkasten vs PARA</title><link href="http://localhost:4000/blog/remembering-what-you-read-zettelkasten-vs-para/" rel="alternate" type="text/html" title="Remembering what you read: Zettelkasten vs PARA" /><published>2020-05-08T00:00:00-07:00</published><updated>2020-05-08T00:00:00-07:00</updated><id>http://localhost:4000/blog/remembering-what-you-read-zettelkasten-vs-para</id><content type="html" xml:base="http://localhost:4000/blog/remembering-what-you-read-zettelkasten-vs-para/">&lt;p&gt;I love reading. But retaining what I read tends to be a challenge. I usually walk away from a book feeling good but with only a faint idea of what was in there. Heck, if I spend a couple hours online I‚Äôll barely remember what articles I read! And it‚Äôs not just me, studies show that &lt;a href=&quot;https://learningsolutionsmag.com/articles/1379/brain-science-the-forgetting-curvethe-dirty-secret-of-corporate-training&quot;&gt;you only retain a tiny percentage of what you read&lt;/a&gt;. I hated the idea of wasting all that time I spent reading, so about a year ago I started looking into ways to retain what I learned.&lt;/p&gt;

&lt;h1 id=&quot;the-contenders&quot;&gt;The Contenders&lt;/h1&gt;

&lt;p&gt;My first attempt led me to Farnam Street‚Äôs tips on &lt;a href=&quot;https://fs.blog/2014/05/remembering-what-you-read/&quot;&gt;remembering what you read&lt;/a&gt;. Their concept of writing your notes on the book itself was liberating (it‚Äôs okay to WRITE in my book?!?). But those notes would then be trapped in the analogue world, locked away until I happened to peruse the book some time in the future.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-05-08-Remember what you read (1).png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FS also suggested writing down the book‚Äôs core ideas from memory right after you finish the book, but this is a process that requires discipline (unless you like testing yourself?) and things requiring discipline have a distressing tendency to not happen.&lt;/p&gt;

&lt;p&gt;Those tips were exciting, but I couldn‚Äôt stick with it.  I needed something different.&lt;/p&gt;

&lt;p&gt;Next I came across the &lt;a href=&quot;https://writingcooperative.com/zettelkasten-how-one-german-scholar-was-so-freakishly-productive-997e4e0ca125&quot;&gt;Zettelkasten note taking method&lt;/a&gt;. Its core idea is to create atomic notes, where each note is about exactly one topic (not more than a few paragraphs tops) and nothing more. Then you file the away in your system by linking that note to other notes which seem most relevant to it. All the notes are written in your own words, so you‚Äôre really writing down your own thoughts here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-05-08-Remember what you read (2).png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The key here is that the linking process &lt;strong&gt;groups relevant notes together&lt;/strong&gt;. Now when you‚Äôre interested in browsing your notes on a given topic, you‚Äôll easily find related notes. You get to see how your ideas relate to each other as well as discover interesting ways they may play off against or even contradict one another.&lt;/p&gt;

&lt;p&gt;But this technique is time intensive. You have to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Save the initial note, paraphrasing what you learned&lt;/li&gt;
  &lt;li&gt;Search for relevant notes to link it to&lt;/li&gt;
  &lt;li&gt;Potentially update your table of contents to find that note more easily later on&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you take a lot of notes, it‚Äôs easy for the stream of incoming notes to quickly leave you overwhelmed. This technique requires a large time commitment and dedication.&lt;/p&gt;

&lt;p&gt;I couldn‚Äôt stick with it.&lt;/p&gt;

&lt;p&gt;Finally I discovered &lt;a href=&quot;https://fortelabs.co/blog/para/&quot;&gt;P.A.R.A&lt;/a&gt;. P.A.R.A. offers a much easier alternative for busy people.&lt;/p&gt;

&lt;p&gt;With P.A.R.A. you organize all your notes by purpose, not by category. Let‚Äôs say you‚Äôre trying to build a SaaS app. You‚Äôll have a folder just for that app. And if you study databases in order to build that app, you‚Äôll file any notes you take inside your app‚Äôs folder, not a ‚Äúdatabases‚Äù folder.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-05-08-Remember what you read (3).png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;What does this do? By creating purpose-based folders and putting all notes related to that &lt;em&gt;purpose&lt;/em&gt; inside it, we‚Äôve created a new way to group relevant notes together. All your notes related to that purpose are available front and center when you open the folder. This lets you avoid the time consuming process of sorting, organizing, and linking your notes in order to make them useful. Just drop the note in the right folder and BAM, that‚Äôs it.&lt;/p&gt;

&lt;p&gt;How do you reference old notes? When you start working on a new project (like a writing assignment) you search the relevant folders and pull out notes that seem relevant to your task. All those notes will go into the new project‚Äôs folder. You‚Äôre effectively discovering related notes on the fly. You‚Äôve avoided the work of double linking and cross referencing your notes. This solution gets you 80% of the way there with 20% of the effort. Just in Time linking.&lt;/p&gt;

&lt;p&gt;When you finish a project, you file away the notes from that project in which ever folder you think they‚Äôll be most useful in, and then archive the project folder.  Now you‚Äôve reset the notes to be discoverable the next time you need them.&lt;/p&gt;

&lt;p&gt;And it‚Äôs not just good for retention. I‚Äôm finding that this purpose-based organization is helping me work much more productively on all my projects!&lt;/p&gt;

&lt;h1 id=&quot;summarize-only-when-needed&quot;&gt;Summarize only when needed&lt;/h1&gt;

&lt;p&gt;Even the step of summarizing what you read is optimized for efficiency. It‚Äôs called &lt;a href=&quot;https://fortelabs.co/blog/progressive-summarization-a-practical-technique-for-designing-discoverable-notes/&quot;&gt;Progressive Summarization&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;With progressive summarization you don‚Äôt bother summarizing what you‚Äôre learning, at least not at first. Instead you take the passages you found most interesting and copy them into your notes. If you ever reread those notes in the future then you can start highlighting the phrases that really spoke to you and if you reread them again, only then will you do the work to summarize the ideas in your own words.&lt;/p&gt;

&lt;p&gt;It‚Äôs not that summarizing your notes from the beginning is bad, but if you procrastinate on it while still expecting yourself to do it then you‚Äôre setting yourself up for failure. Progressive summarization offers you a way to delay summarization while still retaining value.&lt;/p&gt;

&lt;p&gt;Note what‚Äôs happened here: Instead of forcing myself to be disciplined about organizing my notes, P.A.R.A. + Progressive Summarization takes advantage of the times when I‚Äôm &lt;strong&gt;already excited to work on them&lt;/strong&gt;.  Each time I touch the notes, I have to take a small amount of effort which is proportionate to my level of interest in the task.  &lt;strong&gt;We‚Äôve replaced forced discipline with leveraged excitement.&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;limit-what-you-save&quot;&gt;Limit what you save&lt;/h1&gt;

&lt;p&gt;There is one other critical aspect of PARA that‚Äôs required to keep the system from being overwhelming. Successful followers of the Zettelkasten method seem to follow this instinctively, but I haven‚Äôt seen them explicitly mention this:&lt;/p&gt;

&lt;p&gt;You‚Äôre highly encouraged to &lt;strong&gt;limit&lt;/strong&gt; the kind of things you save in your second brain to the following:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Things related to projects you‚Äôre &lt;em&gt;actively&lt;/em&gt; working on. Don‚Äôt store trivia&lt;/li&gt;
  &lt;li&gt;Store things that surprise you: Don‚Äôt store stuff you already know&lt;/li&gt;
  &lt;li&gt;A 12 select problems that you love to think about&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tiago recommends thinking about the 12 problems you care most about and &lt;em&gt;only&lt;/em&gt; store things related to those problems in your notebook (so skip the articles about ancient mummies‚Ä¶unless you‚Äôre an archaeologist). https://fortelabs.co/blog/how-to-use-evernote-for-your-creative-workflow/&lt;/p&gt;

&lt;p&gt;By limiting which topics you put in your second brain you free up more cognitive space to notice what you do store. By storing less you‚Äôll remember more ü§Ø&lt;/p&gt;

&lt;p&gt;Not making your second brain cognitively overwhelming is an under-emphasized part of the PARA system. There shouldn‚Äôt be anything in your project‚Äôs section unless you are actively working on it. Even the other sections are also meant to be pruned on a regular basis so that they only represent your primary interests.  A good rule of thumb: if any folder gains more notes than you can easily skim (~50-100 notes), it might be time to split that folder into two or maybe even delete some notes.&lt;/p&gt;

&lt;h1 id=&quot;in-short&quot;&gt;In short&lt;/h1&gt;

&lt;p&gt;Zettelkasten does have it‚Äôs benefits: If you want to be able to casually browse through your notes, looking for ideas to spark your imagination, Zettelkasten will most likely have superior results since the ideas are already summarized right there for you. Zettelkasten makes it easy to compose essays and put together speeches, but that‚Äôs because you‚Äôve already done the hard work of writing down your thoughts ahead of time. The requirement of linking all notes ahead of time is a HUGE barrier to entry, so it may be best suited to people with a strongly research oriented disposition who‚Äôre already used to similar practices. The fact that there‚Äôs no good software available to help with this makes the process even harder. (Check out &lt;a href=&quot;https://notes.andymatuschak.org/zUw5PuD8op9oq8kHvni6sug6eRTNtR9Wqma&quot;&gt;Andy Matuschak‚Äôs notes&lt;/a&gt; for a gorgeous Zettlekasten example)&lt;/p&gt;

&lt;p&gt;BASB is great for those who don‚Äôt have the time (or willpower) to force themselves to write down notes they may never use. Instead it‚Äôs Just-in-Time philosophy saves many hours and lets you be more productive. Tiago has designed P.A.R.A. to work with most productivity apps, but it really shines when used with Evernote.&lt;/p&gt;

&lt;p&gt;All in all, I‚Äôm finding P.A.R.A. pretty useful so far. It has yet to pass the ultimate test of any knowledge management system: Will I still be using it three months from now? (ask me after July). I‚Äôm already noticing productivity boosts by using the PARA method to store notes for all my projects, so prospects are looking good üòÅ&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="productivity" /><summary type="html">I spent over a year researching better ways to take notes to remember what I read, and here's what I found.</summary></entry><entry><title type="html">Quickly Building Products for ACTUAL Customers</title><link href="http://localhost:4000/blog/quickly-building-products-for-actual-customers/" rel="alternate" type="text/html" title="Quickly Building Products for ACTUAL Customers" /><published>2020-04-10T00:00:00-07:00</published><updated>2020-04-10T00:00:00-07:00</updated><id>http://localhost:4000/blog/quickly-building-products-for-actual-customers</id><content type="html" xml:base="http://localhost:4000/blog/quickly-building-products-for-actual-customers/">&lt;p&gt;&lt;em&gt;This is my&lt;/em&gt; &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248271817258622978&quot;&gt;&lt;em&gt;tweetstorm&lt;/em&gt;&lt;/a&gt; &lt;em&gt;on key aspects to focus on when you‚Äôre building a SaaS service. It details how features that seem critical may not actually be that important.  Experiment to see what your &lt;strong&gt;actual&lt;/strong&gt; customers are demanding, and focus 100% of your effort on that. It‚Äôs okay to acquire technical debt along the way&lt;/em&gt;&lt;/p&gt;

&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;1/ &lt;a href=&quot;https://twitter.com/Google?ref_src=twsrc%5Etfw&quot;&gt;@Google&lt;/a&gt; SREs released a free book on Building Secure and Reliable Systems&lt;a href=&quot;https://t.co/qr725ptjpQ&quot;&gt;https://t.co/qr725ptjpQ&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;It&amp;#39;s a great book, but not all the requirements of a huge international company with 100,000 employees will apply to your company&lt;br /&gt;&lt;br /&gt;Carefully pick &amp;amp; choose what&amp;#39;s relevant to you&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248271817258622978?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;2/ Sometimes you need to see what your customers actually care about (e.g. better security vs shiny new feature)&lt;br /&gt;&lt;br /&gt;Based on their desires, toiling to improve reliability/security may lead to a secure service which runs out of cash before it can make money&lt;a href=&quot;https://t.co/uy9ZZFLEX2&quot;&gt;https://t.co/uy9ZZFLEX2&lt;/a&gt;&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248271818261024771?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;3/ Unpopular opinion:&lt;br /&gt;&lt;br /&gt;This is what Zoom did. They deprioritized security in favor of the features _their customers_ voted for with their wallets.&lt;br /&gt;&lt;br /&gt;Reliability and Ease of use were the two biggest ones&lt;br /&gt;&lt;br /&gt;Back then anyways&lt;br /&gt;&lt;br /&gt;Not working on security was a form of Technical Debt&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248271819196354561?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;4/ And now it&amp;#39;s time for them to pay off that Technical Debt since their customers are actually asking for that now&lt;br /&gt;&lt;br /&gt;(and again voting with their wallets)&lt;br /&gt;&lt;br /&gt;But note that Zoom was unlikely to even reach this stage if they hadn&amp;#39;t placed their bets where they did the past few years&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248271820299489281?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;5/ Deliberately choosing what &amp;quot;best practices&amp;quot; you spend your time and effort on implementing and which ones to ignore for later is how you get Technical Debt&lt;br /&gt;&lt;br /&gt;And like Financial Debt, it can be good for you as long as you weight the costs carefully&lt;a href=&quot;https://t.co/GfH5xNl83a&quot;&gt;https://t.co/GfH5xNl83a&lt;/a&gt;&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248272435020890115?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;6/ Tech Debt buys you Time + Opportunity&lt;br /&gt;&lt;br /&gt;Spend it on MVPs, validating your solutions are what your customers actually care about&lt;br /&gt;&lt;br /&gt;And then go sell it to them&lt;a href=&quot;https://t.co/GgVV6lJI1Q&quot;&gt;https://t.co/GgVV6lJI1Q&lt;/a&gt;&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248273013830610944?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;7/ Part of that is validating that what you&amp;#39;re building is a thing you customers will actually yank out their wallet for and throw it at you&lt;br /&gt;&lt;br /&gt;(Nice-to-have&amp;#39;s don&amp;#39;t cause this effect)&lt;br /&gt;&lt;br /&gt;A common Failure Mode: Confusing your Users for your Actual Customers&lt;a href=&quot;https://t.co/WWxnxWpqHd&quot;&gt;https://t.co/WWxnxWpqHd&lt;/a&gt;&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248273015298617351?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;8/ This process of focusing all your efforts on exactly the things your customers actually want is what &lt;a href=&quot;https://twitter.com/b0noi?ref_src=twsrc%5Etfw&quot;&gt;@b0noi&lt;/a&gt; calls User Oriented Development Process&lt;a href=&quot;https://t.co/8OpJfuikKk&quot;&gt;https://t.co/8OpJfuikKk&lt;/a&gt;&lt;br /&gt;&lt;br /&gt;(&amp;quot;User&amp;quot; means &amp;quot;Customer&amp;quot; there)&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248273016422715393?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;9/ Another common Failure Mode: &lt;br /&gt;&lt;br /&gt;Trying to scale waaaay beyond what&amp;#39;s actually needed&lt;a href=&quot;https://t.co/lWAfdxjZsH&quot;&gt;https://t.co/lWAfdxjZsH&lt;/a&gt;&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248273017374793728?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;
&lt;div class=&quot;jekyll-twitter-plugin&quot;&gt;&lt;blockquote class=&quot;twitter-tweet&quot; data-conversation=&quot;none&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;10/ So what to focus on? It depends on *your* situation!&lt;br /&gt;&lt;br /&gt;If your customers care most about security, focus on that&lt;br /&gt;&lt;br /&gt;If they want reliability, give them that&lt;br /&gt;&lt;br /&gt;If they just want to watch cat videos then move fast &amp;amp; break things&lt;br /&gt;&lt;br /&gt;Your job is to: Offer, Discover, Adjust, Repeat&lt;/p&gt;&amp;mdash; Zain Rizvi (@ZainRzv) &lt;a href=&quot;https://twitter.com/ZainRzv/status/1248273236049063937?ref_src=twsrc%5Etfw&quot;&gt;April 9, 2020&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;/div&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="SaaS" /><summary type="html">Features that seem critical may not actually be that important. Experiment to see what your *actual* customers are demanding, and focus 100% on that.</summary></entry><entry><title type="html">The Truth about VPC Security Controls</title><link href="http://localhost:4000/blog/the-truth-about-vpc-security-controls/" rel="alternate" type="text/html" title="The Truth about VPC Security Controls" /><published>2020-02-21T00:00:00-08:00</published><updated>2020-02-21T00:00:00-08:00</updated><id>http://localhost:4000/blog/the-truth-about-vpc-security-controls</id><content type="html" xml:base="http://localhost:4000/blog/the-truth-about-vpc-security-controls/">&lt;p&gt;GCP‚Äôs &lt;a href=&quot;https://cloud.google.com/vpc-service-controls&quot;&gt;VPC Service Controls&lt;/a&gt; protection is often described as a virtual firewall for your GCP projects.  That‚Äôs a useful mental model for your company‚Äôs decision makers to think with, but the analogy quickly breaks down if you‚Äôre an engineer trying to actually implement VPC-SC protection for your GCP projects.&lt;/p&gt;

&lt;p&gt;I learned that the hard way.&lt;/p&gt;

&lt;p&gt;Here I‚Äôll describe just what VPC-SC is, why it was needed, and a big mistake I made which you reeeally want to make sure you avoid.&lt;/p&gt;

&lt;h1 id=&quot;what-problem-is-vpc-sc-supposed-to-solve-anyways&quot;&gt;What Problem is VPC-SC Supposed to Solve Anyways?&lt;/h1&gt;

&lt;p&gt;The core problem VPC-SC is meant to solve is to protect companies against &lt;strong&gt;data exfiltration&lt;/strong&gt;.  That‚Äôs a fancy way to describe preventing adversaries from copying your private data off of your servers and onto their own.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-02-21-vpc-sc-truth-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can setup many types of protections to prevent attackers from getting access to your machines (let‚Äôs strong with decent passwords, shall we?), but following the principle of &lt;a href=&quot;https://www.imperva.com/learn/application-security/defense-in-depth/&quot;&gt;defense in depth&lt;/a&gt;, enterprises with more critical data protection requirements sometimes need an additional layer of protection which says ‚ÄúEven if someone hacks into our machines, joke‚Äôs on them. They still can‚Äôt steal our data!‚Äù That‚Äôs the core problem we‚Äôre trying to solve here.&lt;/p&gt;

&lt;p&gt;This problem has been around for a while. How was it solved in the pre-cloud era?&lt;/p&gt;

&lt;p&gt;Back then, companies would have a private corporate network. All employee computers would be inside that network, and that network would have a set of strict firewall rules setup to prevent data from being passed to the outside world.  The firewall would only be opened up for a few, strictly vetted sites that employees had real business need to access.&lt;/p&gt;

&lt;p&gt;This way, even if an attacker gained access to a machine they still would not be able to send a copy of the data to themselves.  The firewall would block any such attempts.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-02-21-vpc-sc-truth-2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now what changes if you move to the cloud?  Not too much actually!&lt;/p&gt;

&lt;p&gt;You can define firewall rules for your cloud VMs as well and you can set those up to match very similar rules to what your local company network had.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-02-21-vpc-sc-truth-3.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But what if you wanted to use any of the other mouth watering array of services GCP offers?  Things like blob storage, pub sub, or juptyer notebooks as a service?&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-02-21-vpc-sc-truth-4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Those services live outside the reach of your firewalls.  They‚Äôre run on servers which are the entry point for resources owned by all GCP customers.&lt;/p&gt;

&lt;p&gt;The usual solution of opening up a firewall hole to allow traffic just to those services doesn‚Äôt quite work.  Take Google Cloud Storage (GCS) for example, it‚Äôs specifically designed to store data so it would be trivial for an attacker to take your secret data, push it to their own GCS bucket and then download the data from there at their leisure.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-02-21-vpc-sc-truth-5.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Some companies worked around this problem by self-hosting their own versions of these services within their private corporate networks.  That‚Äôs an option, but it‚Äôs expensive. You have to run, debug, maintain, and upgrade both the software and servers, all by yourself.  Your dev ops team is cursed to toil away in the kitchen making boiled chicken, while longingly looking upon the &lt;a href=&quot;https://images.app.goo.gl/KedFe6Tui7kKR7cc7&quot;&gt;duck confit&lt;/a&gt; delivered to their neighbor‚Äôs doorsteps.&lt;/p&gt;

&lt;p&gt;VPC-SC provides a better way.&lt;/p&gt;

&lt;h1 id=&quot;vpc-sc-to-the-rescue&quot;&gt;VPC-SC to the Rescue&lt;/h1&gt;

&lt;p&gt;At a high level, VPC-SC controls are settings you can define across your projects that help you eat from the GCP buffet without worrying about &lt;a href=&quot;https://youtu.be/YbFnrkeH7IA?t=11&quot;&gt;an alligator eating you&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;These settings are called your VPC-SC perimeter.  You create and enable a VPC-SC perimeter (the virtual firewall) by defining three things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A list of GCP services that you want to set on lockdown mode&lt;/li&gt;
  &lt;li&gt;The specific projects of yours that the lockdown mode should be applied to&lt;/li&gt;
  &lt;li&gt;Exceptions you want to make to the above policy (via &lt;a href=&quot;https://cloud.google.com/access-context-manager/docs&quot;&gt;Access Context Manager&lt;/a&gt;), but let‚Äôs ignore this category&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let‚Äôs call the set of projects in the perimeter P. By adding GCP services and projects to the perimeter you‚Äôre saying you want to see the following behavior implemented by each of those services:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data Ingress limits: the service shouldn‚Äôt allow anything outside the P projects in to read/write data to P. So data is never read from outside the perimeter.&lt;/li&gt;
  &lt;li&gt;Data Egress limits: The service shouldn‚Äôt allow projects P to write data anywhere &lt;em&gt;except&lt;/em&gt; in one of the P projects. So data never gets written outside the perimeter.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The above two clauses put together tell GCP Services to make sure your data stays inside your projects.&lt;/p&gt;

&lt;p&gt;So you‚Äôve combined the traditional firewall + DNS rules that were used to protect computers, and added a layer of VPC-SC service level protection on top of that.  These combine to protect your resources from data exfiltration.&lt;/p&gt;

&lt;p&gt;How? Now, the only way to access your project‚Äôs data is from your VM, which is protected by your custom firewall rules.  Even if an adversary manages to get a hold of your GCP credentials they still wouldn‚Äôt be able to steal your data. They would first have to breach your firewall to enter your VPC-SC perimeter! (Defense in depth!)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-02-21-vpc-sc-truth-6.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And that‚Äôs how you get the virtual firewall!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The more astute among you may have noticed that the VPC-SC controls actually have nothing to do with your VPC network.  I never asked, but I assume the name VPC-SC was chosen for marketing purposes to make the ‚Äòvirtual firewall‚Äô analogy easier to accept&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-big-misunderstanding&quot;&gt;The Big Misunderstanding&lt;/h1&gt;

&lt;p&gt;There‚Äôs one horrible assumption that people tend to make when setting up VPC-SC networks.  I made this mistake too and spent a long time trying to debug it before I realized what I was doing wrong.&lt;/p&gt;

&lt;p&gt;Notice how you‚Äôre adding services into your VPC-SC perimeter to enable the ‚Äúlockdown mode‚Äù?  What happens if you don‚Äôt add some service to the perimeter?  My na√Øve assumption was that it would be blocked and inaccessible to my VMs.&lt;/p&gt;

&lt;p&gt;That is absolutely, completely, 100% not the case.&lt;/p&gt;

&lt;p&gt;In fact, if you don‚Äôt add a service to your VPC-SC perimeter then you‚Äôve basically left the route open for your internal VMs to send data to that service but neglected to lock down that service itself. Chickens are in the hen house, but the door is left wide open.&lt;/p&gt;

&lt;p&gt;Here comes the fox ready to exfiltrate your data!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-02-21-vpc-sc-truth-7.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In case that wasn‚Äôt clear: *You must to &lt;strong&gt;opt-in&lt;/strong&gt; to &lt;strong&gt;every__ service ***&lt;em&gt;that you want to have locked-down&lt;/em&gt;. Opting-out means **zero&lt;/strong&gt; protection.&lt;/p&gt;

&lt;p&gt;There were probably good technical reasons for setting this up as the default behavior. The first guess which comes to mind would be that not all GCP services support the VPC-SC lockdown yet. But boy, you can really get caught with your pants down if you don‚Äôt see this one coming.&lt;/p&gt;

&lt;p&gt;How do you protect yourself against this?  First step is to include all services that you actually plan to use in your VPC-SC perimeter.  Then, block all the services that you do not plan to use.  I‚Äôm not sure what the recommended way to do this is (probably something at either the DNS or the IAM levels) but that‚Äôs what you‚Äôll want to do.  Otherwise you‚Äôll have left a hole wide open that‚Äôs big enough for an adversary to drive a Humvee full of chickens through.&lt;/p&gt;

&lt;p&gt;Please don‚Äôt do that&lt;/p&gt;

&lt;h1 id=&quot;the-power-is-yours&quot;&gt;The Power is Yours&lt;/h1&gt;

&lt;p&gt;There‚Äôs a quick overview of what VPC-SC controls offer you and what they don‚Äôt.  Hope this helped you get a better understanding of how to set it up.&lt;/p&gt;

&lt;p&gt;If you have any thoughts, war stories, or corrections, shout out in the comments and let me know!&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="Technical" /><category term="GCP" /><summary type="html">GCP's VPC Service Controls protection is often described as a virtual firewall for your GCP projects. That metaphor quickly breaks down if you're trying to actually add it to your GCP projects. I learned that the hard way.</summary></entry><entry><title type="html">So you want to do Deep Work?</title><link href="http://localhost:4000/blog/so-you-want-to-deep-work/" rel="alternate" type="text/html" title="So you want to do Deep Work?" /><published>2020-01-23T00:00:00-08:00</published><updated>2020-01-23T00:00:00-08:00</updated><id>http://localhost:4000/blog/so-you-want-to-deep-work</id><content type="html" xml:base="http://localhost:4000/blog/so-you-want-to-deep-work/">&lt;p&gt;Deep Work has been called ‚Äúthe ability to focus without distraction on a cognitively demanding task.‚Äù  Other people call this being in the state of ‚Äúflow‚Äù or ‚Äúbeing in the zone‚Äù where you can effortlessly focus on your work and be incredibly productive.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;‚Äú‚ÄòThe best moments usually occur when a person‚Äôs body or mind is stretched to its limits in a voluntary effort to accomplish something difficult and worthwhile.‚Äô‚Ä¶ this mental state [is] Flow‚Äù&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In this information era where all mechanical tasks are being automated, in order to be successful you need to be able to do what machines cannot: be creative.  And creativity is something you can generate on demand through deep work, and in his book ‚ÄúDeep Work‚Äù Cal explains how you can achieve it.&lt;/p&gt;

&lt;p&gt;Below are the key takeaways I had from his book, with a bunch of my own thoughts sprinkled in.&lt;/p&gt;

&lt;h1 id=&quot;your-motivation-is-the-key&quot;&gt;Your Motivation is the Key&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;‚Äúthe skillful management of attention is‚Ä¶the key to improving virtually every aspect of your experience.‚Äù&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Deep Work requires you to concentrate on a topic for long stretches of time.  This is an extremely challenging task unless the topic is something that you feel highly motivated to work on.&lt;/p&gt;

&lt;p&gt;What happens if you try to work on a task you‚Äôre not motivated about? You procrastinate. And delay. And do almost anything else except work on that one task.  You might slowly make progress, but you‚Äôll be terribly inefficient.&lt;/p&gt;

&lt;p&gt;But if you‚Äôre motivated to do something, we can spend hours working on it non-stop and not even feel tired afterwards.  We need to harness this motivation.&lt;/p&gt;

&lt;p&gt;Even if we feel motivated for a while, our brains are fickle things and sometimes get distracted anyways. It helps to have additional layers of motivation to help us stay motivated to work towards our goals.  It‚Äôs like multiple hands pushing you in the direction you want to go.&lt;/p&gt;

&lt;p&gt;Here are some specific tactics to help us stay motivated:&lt;/p&gt;

&lt;h2 id=&quot;tactic-1-focus-on-what-you-really-care-about&quot;&gt;Tactic #1: Focus on What You REALLY Care About&lt;/h2&gt;

&lt;p&gt;The first step to being strongly motivated is to focus &lt;em&gt;only&lt;/em&gt; on the tasks you really care about.&lt;/p&gt;

&lt;p&gt;You need to manage your attention so that you don‚Äôt have to force yourself to work.  Don‚Äôt make yourself say ‚Äòno‚Äô to things you want to do.  Instead, find the productive things that you are really longing to do and say ‚Äòyes‚Äô to them.  That ‚Äòyes‚Äô will be effortless.&lt;/p&gt;

&lt;p&gt;For example, you didn‚Äôt have to force yourself away from Facebook to watch the last Avengers movie.  When you had a chance to watch the movie, Facebook didn‚Äôt even enter your mind.&lt;/p&gt;

&lt;p&gt;Find work that captures your attention the same way&lt;/p&gt;

&lt;p&gt;&lt;em&gt;‚ÄúTo win the battle for willpower, don‚Äôt try to say ‚Äòno‚Äô to the things you want to avoid. Instead try to say ‚Äòyes‚Äô to the subject that arouses terrifying longing, and let that terrifying longing crowd out everything else‚Äù&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;tactic-2-create-fast-feedback-loops&quot;&gt;Tactic #2: Create Fast Feedback Loops&lt;/h2&gt;

&lt;p&gt;This is both a productivity tip and a motivational hack.&lt;/p&gt;

&lt;p&gt;Fast &lt;a href=&quot;https://fs.blog/2014/05/improving-your-performance/&quot;&gt;feedback loops&lt;/a&gt; are when you can quickly measure a result which tells you how effectively you‚Äôre working.&lt;/p&gt;

&lt;p&gt;Creating feedback loops help you figure out how we‚Äôll you‚Äôre progressing towards your goal.  The faster you can tell that you‚Äôre veering off track, the better.&lt;/p&gt;

&lt;p&gt;And seeing that you‚Äôre doing good work (or that you need to improve) can push you do keep going or work harder.  Conversely, if you can‚Äôt see the effects of your actions, you‚Äôll stop caring (goodbye motivation).&lt;/p&gt;

&lt;p&gt;Cal specifically mentions measuring what he calls ‚Äòlead measures‚Äô, which are items which imply you will be successful (e.g. hours spent in deep work, or mini tasks that you‚Äôve completed).  He contrasts that to ‚Äòlag measures‚Äô like number of sales, since the latter takes a lot longer to acquire, meaning it‚Äôll take a lot longer to get that feedback.&lt;/p&gt;

&lt;p&gt;It can be tricky to identify good lead measures, but they should be behaviors that would drive success on the lag measures.  But the general idea is to see how you can get feedback as fast as possible, which is in line with many other popular philosophies such as MVPs and Fail Fast.&lt;/p&gt;

&lt;h2 id=&quot;tactic-3-compete-and-win&quot;&gt;Tactic #3: Compete and Win&lt;/h2&gt;

&lt;p&gt;Add to your motivation by competing against yourself (or others) with a scoreboard.  Cal suggests that people play differently when they‚Äôre keeping score.  This is really another way of using your lead measures, but you are now attaching a goal to the lead measures and getting your psychology involved as well.&lt;/p&gt;

&lt;p&gt;Note that it‚Äôs best if you don‚Äôt make this a public competition, otherwise you run the risk of optimizing for the wrong metric (the score board) instead of the actual value the score board was meant to represent.&lt;/p&gt;

&lt;p&gt;Examples of score boards:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Outcomes from your feedback loops&lt;/li&gt;
  &lt;li&gt;Number of hours spent in deep work per day/week&lt;/li&gt;
  &lt;li&gt;Number of lead measures&lt;/li&gt;
  &lt;li&gt;Number of customer sign ups&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tactic-4-regular-accountability&quot;&gt;Tactic #4: Regular Accountability&lt;/h2&gt;

&lt;p&gt;Have regular meetings of any team that owns a wildly important goal.  This could be you setting up a time (weekly or daily) to go over the past weeks scores and plan how to improve the next week.  This also plays into the feedback loops that you‚Äôre creating and is another angle through which you can make sure your motivation stays high.  Social accountability can be a surprisingly motivating lever.&lt;/p&gt;

&lt;p&gt;If you‚Äôre working solo, you can create accountability in other ways.  You can commit to giving regular updates to a group of friends, or to post them on a public forum where your peers will see it.&lt;/p&gt;

&lt;p&gt;This tactic can be seen as a variant of a precommitment device&lt;/p&gt;

&lt;h2 id=&quot;tactic-5-work-with-great-intensity&quot;&gt;Tactic #5: Work with Great Intensity&lt;/h2&gt;

&lt;p&gt;Take your goals, estimate how long it‚Äôll take to complete, and give yourself a drastically reduced deadline. Commit to it publicly if possible, and then work intensely to make it happen.&lt;/p&gt;

&lt;p&gt;This is kind of like how in school you it would be impossible to write that essay a week before it was due.  Yet the day before the deadline words would suddenly pour forth from your fingertips like magic.&lt;/p&gt;

&lt;p&gt;Personally, I find it next to impossible to take a self-imposed deadline seriously.  I have to pair it with external accountability by telling someone else when about that deadline.  Knowing that I‚Äôll have to report my status to that second person suddenly makes that deadline real.&lt;/p&gt;

&lt;h1 id=&quot;create-a-structure-for-your-deep-work&quot;&gt;Create a Structure for your Deep Work&lt;/h1&gt;

&lt;p&gt;Many creatives know the pain of sitting in front of a black piece of paper and then thinking ‚Äònow what‚Äô?  The best people use a formula that works for them.  It seems counterintuitive to use a formula for creativity, but people are most creative when we are given certain limitations (otherwise we risk &lt;a href=&quot;https://hbr.org/2009/09/death-by-information-overload&quot;&gt;information overload&lt;/a&gt;).  Those people have a specific pattern of actions that help them focus and concentrate, and you‚Äôll want to develop one for yourself that you‚Äôll use to do your deep thinking.&lt;/p&gt;

&lt;p&gt;There‚Äôs no one fixed formula because it‚Äôll vary based on your industry, the type of work you do, and even your personality.&lt;/p&gt;

&lt;p&gt;However, you can take the following formula as a starting point.  Then overtime you‚Äôll build on it and adjust it to meet your own needs&lt;/p&gt;

&lt;p&gt;Starting structure:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Carefully review the relevant &lt;strong&gt;variables&lt;/strong&gt; for solving the problem (the things you can affect) and store them in memory&lt;/li&gt;
  &lt;li&gt;Define the &lt;strong&gt;next-step&lt;/strong&gt; question you need to answer using those variables. Now you have a specific target for your attention&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Focus&lt;/strong&gt; on your question and try to find an answer using the variables&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Consolidate&lt;/strong&gt; your gains by reviewing clearly the answer you arrived at&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;There are also a couple pitfalls in your thinking you should watch out for:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Distractions:&lt;/strong&gt; thinking about other things besides the really important goal you have&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Looping:&lt;/strong&gt; Going over the same problem again and again, rehashing old results without diving deeper into it. When you notice the loop, catch yourself and shift your attention to the next step&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;discarding-distractions--embracing-boredom--finding-focus&quot;&gt;Discarding Distractions + Embracing Boredom = Finding Focus&lt;/h1&gt;

&lt;p&gt;You have to be able to focus on your deep work.  Without this skill, your mind will constatly be wandering to all the distractions constantly bombarding you for attention.&lt;/p&gt;

&lt;p&gt;Being able to focus is a skill in and of itself, and you can develop that skill. When you concentrate on something regularly every day (e.g. meditation) you are building up your concentration muscles which will help you have laser focus in other areas of your life.&lt;/p&gt;

&lt;p&gt;The way you get better at focusing is to force yourself to get distracted less.&lt;/p&gt;

&lt;p&gt;Distractions are things like:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Email&lt;/li&gt;
  &lt;li&gt;Social media &amp;amp; web surfing&lt;/li&gt;
  &lt;li&gt;Most of the internet really (you can define specific kinds of internet use as acceptable if it‚Äôs critical to your work)&lt;/li&gt;
  &lt;li&gt;99% of alerts on your phone&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Don‚Äôt take breaks from Distraction, take breaks from Focus.&lt;/strong&gt; Focus should  be your default state of mind.  Only allow yourself to be distracted at predefined times.&lt;/p&gt;

&lt;p&gt;You can schedule the occasional break from focus where you can give in to distractions. It has a side benefit of also training yourself to delay gratification.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implementation tips:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;If you need that distraction frequently (e.g. you‚Äôre expected to be responsive to email) , then schedule shorter, more frequent, ‚Äúdistraction‚Äù breaks&lt;/li&gt;
  &lt;li&gt;Absolutely no distractions during the distraction free time. You must resist temptation, even when it seems important, this is training your brain&lt;/li&gt;
  &lt;li&gt;Schedule distraction time at home as well as work. Your brain should be trained to always be in focus mode, even if the thing you‚Äôre focusing on is family.&lt;/li&gt;
  &lt;li&gt;Turn off all non-critical notifications on your phone&lt;/li&gt;
  &lt;li&gt;Enable Do not Disturb mode on your phone by default, maybe just allowing phone calls to come through.  You can check your phone for notifications during your distraction breaks or set it up to automatically disable Do not Disturb mode during your breaks&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;cut-out-your-time-wasters&quot;&gt;Cut out your Time Wasters&lt;/h1&gt;

&lt;p&gt;Eliminate activities that don‚Äôt help you achieve your goals.&lt;/p&gt;

&lt;p&gt;Cal called this rule ‚ÄúQuit Social Media‚Äù but it‚Äôs really about removing your biggest time wasters.  The logic also applies to TV, YouTube, web surfing, etc.&lt;/p&gt;

&lt;p&gt;Social media (and your other time wasters) are tools. They have both positive and negative effects, though the negative comes much more easily.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The Craftsman Approach to Tool Selection:&lt;/strong&gt; Identify the core factors that determine success and happiness in your professional and personal life. Adopt a tool only if its positive impacts on these factors substantially outweighed its negative impacts&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Apply the 80/20 Rule to Your Internet Habits.&lt;/strong&gt; Figure out which 20% of your online time gives you 80% of the value.&lt;/p&gt;

&lt;p&gt;To do this you need to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Identify the main high-level goals in both your professional and personal life&lt;/li&gt;
  &lt;li&gt;For each goal, list the two or three most important activities that help you satisfy the goal.
    &lt;ul&gt;
      &lt;li&gt;The activities should be specific enough to allow you to clearly picture doing them, but general enough to not be tied to a one-time outcome&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Consider the network tools you currently use
    &lt;ul&gt;
      &lt;li&gt;For each, ask whether the tool has a substantially positive, substantially negative, or little impact on the above identified activities.&lt;/li&gt;
      &lt;li&gt;Only use tools that are substantially positive&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Don‚Äôt Use the Internet to Entertain Yourself!&lt;/strong&gt; Make deliberate use of your time outside work.  The internet is like a time machine that fast forwards you through hours of your life (like in the movie ‚Äò&lt;a href=&quot;https://www.imdb.com/title/tt0000389860/&quot;&gt;Click&lt;/a&gt;‚Äô).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Put more thought into your leisure time.&lt;/strong&gt; Think ahead how you want to spend you free time later that day or on a future day.  You can use that time to focus on things shown to &lt;a href=&quot;https://www.bakadesuyo.com/2016/07/how-to-find-happiness-3/&quot;&gt;increase happiness&lt;/a&gt;, such as improving your relationships, engaging in structured hobbies, enjoy nature, etc.&lt;/p&gt;

&lt;h1 id=&quot;remove-shallow-work-as-much-as-possible&quot;&gt;Remove Shallow Work as much as Possible&lt;/h1&gt;

&lt;p&gt;Shallow work consists of noncognitively demanding, logistical style tasks, that you can often perform while distracted (e.g. filling forms, sending emails). Essentially it‚Äôs any work that‚Äôs not deep work.&lt;/p&gt;

&lt;p&gt;These efforts tend not to create much new value in the world and are easy to replicate .&lt;/p&gt;

&lt;p&gt;Shallow work that increasingly dominates the time and attention of knowledge workers is less vital than it often seems in the moment. Replacing shallow work with deep work means you do more work which is actually profitable. (Of course, there is a limit to how much shallow work you can actually cut out)&lt;/p&gt;

&lt;p&gt;Deep work is cognitively exhausting. In the beginning, an hour a day is a reasonable amount of deep work time. Experts can do up to four hours, but rarely more.&lt;/p&gt;

&lt;p&gt;The rest of the time can be spent in shallow work.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;following are tactics designed to push you to not waste time on shallow work&lt;/strong&gt;.  They‚Äôre all designed around getting you to deliberately choose how you‚Äôre spending your time&lt;/p&gt;

&lt;h2 id=&quot;tactic-1-schedule-every-minute-of-your-day&quot;&gt;Tactic #1: Schedule Every Minute of Your Day&lt;/h2&gt;

&lt;p&gt;At the beginning of each workday, divide your day into blocks and write what activity you‚Äôll be doing in each block.&lt;/p&gt;

&lt;p&gt;Issues that‚Äôll come up: your estimates were wrong, and other obligations/interruptions will come your way unexpectedly&lt;/p&gt;

&lt;p&gt;That‚Äôs okay, just remake your schedule the first chance you get. It‚Äôs okay if you have to redo your schedule a dozen times a day&lt;/p&gt;

&lt;p&gt;The goal here is to force yourself to be conscious about how you‚Äôre spending your time. It‚Äôs a way to make you think ‚Äúwhat‚Äôs the best thing I could be doing with my remaining time?‚Äù This question will make you less likely to spend time on less productive tasks.&lt;/p&gt;

&lt;p&gt;Tactic: add overflow conditional blocks, blocks where you were doing Activity A before and you‚Äôll continue doing it if it takes longer than expected, but if you finish A then you‚Äôll do Activity B instead&lt;/p&gt;

&lt;p&gt;Tactic: include a ‚Äòmiscellaneous‚Äô block for handling generic things that need to be done (email, interruptions, etc)&lt;/p&gt;

&lt;h2 id=&quot;tactic-2-finish-your-work-at-the-same-time-each-day&quot;&gt;Tactic #2: Finish your Work at the Same Time Each Day&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Fixed-schedule productivity:&lt;/strong&gt; have a firm goal of not working past a certain time, then work backwards to find productivity strategies that allow you to satisfy this declaration.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;You drop what can‚Äôt be done, and find ways to maximize what you want to do given your limited time budget&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Tactic&lt;/strong&gt;: set drastic quotas on the major sources of &lt;em&gt;shallow&lt;/em&gt; endeavors while protecting the &lt;em&gt;deep&lt;/em&gt; efforts&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Be asymmetric in the culling your activities to make the fixed-schedule productivity work: cut the shallow while preserving the deep&lt;/li&gt;
  &lt;li&gt;Limiting your time forces you to carefully think about your actions, forcing you to be more productive&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a &lt;strong&gt;meta-habit&lt;/strong&gt; that‚Äôs simple to adopt but broad in impact&lt;/p&gt;

&lt;h1 id=&quot;give-yourself-down-time&quot;&gt;Give Yourself Down Time&lt;/h1&gt;

&lt;p&gt;Aka: Don‚Äôt take your work home&lt;/p&gt;

&lt;p&gt;You need to be able to relax your brain when you‚Äôre not working, so that it‚Äôs ready to again give a 100% when you start working again.  If you don‚Äôt have any problems with that, then go ahead and skip this section.  If you find yourself thinking about work when you‚Äôre sitting with your family, then read on.&lt;/p&gt;

&lt;p&gt;One tactic for this: Have a Shutdown Ritual&lt;/p&gt;

&lt;p&gt;The idea is that if you find yourself thinking about things you need to do, you need to come up with a system that you trust to make sure that everything important will be taken care of.  GTD, bullet journaling, BASB are all different systems meant to achieve this goal, and they all revolve around the idea of documenting your task list in a way that you trust.&lt;/p&gt;

&lt;p&gt;At the end of your workday, have a shutdown procedure so that your brain can stop thinking about what you still need to do. This frees your brain up so that it can rest and recover in the evening.&lt;/p&gt;

&lt;p&gt;The process should be:&lt;/p&gt;

&lt;p&gt;First, ensure every incomplete task, goal, or project has been reviewed and that for each you have confirmed that either&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;You have a plan you trust for its completion&lt;/li&gt;
  &lt;li&gt;It‚Äôs captured in a place where it will be revisited when the time is right&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you follow a GTD, bullet journaling, or BASB type system, that system should be meeting the above needs.  If it doesn‚Äôt, it‚Äôs a good idea to analyze your routine to see why it falls short and seeing what you can tweak to fix that.&lt;/p&gt;

&lt;p&gt;Cal adds that when you‚Äôre done, have a set phrase you say that indicates completion (e.g. ‚ÄúShutdown complete‚Äù).  I never did this part myself, but I can see how the routine-ness of it could help flick a mental trigger for some folks.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;Deep Work can be an incredibly rewarding activity, both personally and professionally.&lt;/p&gt;

&lt;p&gt;In short, the keys to successfully engaging in deep work are to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Work on tasks you find Highly Motivating&lt;/strong&gt; and then motivate yourself some more&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Develop a Structure for how you‚Äôll do deep work&lt;/strong&gt;.  Don‚Äôt just sit there waiting for inspiration to strike&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Train yourself to Get Better at Focusing&lt;/strong&gt;.  You can‚Äôt do deep work if you constantly get distracted&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Get Rid of your Time Wasters&lt;/strong&gt;.  I‚Äôm looking at you, Facebook&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Remove Shallow Work as much as possible&lt;/strong&gt;.  Sometimes that work is important, but often it‚Äôs not really&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Save some Down Time to Recover&lt;/strong&gt;.  Deep work is hard, give your brain time to rest&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you found these tips useful, sign up below to get new articles I write at the intersection of self-improvement, psychology, business, and technology.&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="Deep Work" /><category term="Psychology" /><category term="Productivity" /><summary type="html">In this information era where all mechanical tasks are being automated, in order to be successful you need to be able to do what machines cannot: be creative. And creativity is something you generate on demand through Deep Work</summary></entry><entry><title type="html">How to setup a Free Custom Domain Email Address</title><link href="http://localhost:4000/blog/how-to-setup-a-free-custom-domain-email-address/" rel="alternate" type="text/html" title="How to setup a Free Custom Domain Email Address" /><published>2020-01-15T00:00:00-08:00</published><updated>2020-01-15T00:00:00-08:00</updated><id>http://localhost:4000/blog/how-to-setup-a-free-custom-domain-email-address</id><content type="html" xml:base="http://localhost:4000/blog/how-to-setup-a-free-custom-domain-email-address/">&lt;p&gt;I recently discovered that it‚Äôs possible to combine any domain that you own with your Gmail account and a free MailGun account to get a free custom domain email address!&lt;/p&gt;

&lt;p&gt;When you‚Äôre done following the below instructions you‚Äôll be able to send and receive emails addressed to you@yourdomain.com directly from your Gmail inbox.&lt;/p&gt;

&lt;h1 id=&quot;step-1---buy-a-domain&quot;&gt;Step 1 - Buy a domain&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-01-14-namecheap logo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Okay, so you still have to pay to own your domain, but the rest is free. And if you want a custom domain email address, then chances are you‚Äôre interested in your professional reputation. Owning your own domain is a good idea even if you don‚Äôt plan to start your own sure just yet. I held off on it a couple years and that was enough for a law student to grab zainrizvi.com -_-&lt;/p&gt;

&lt;p&gt;I prefer to buy my domains through namecheap.com, though pretty much any company would work. Use whatever you like, but don‚Äôt let the decision of which site to use to stop you from buying your domain! (Use namecheap.com if you‚Äôre uncertain)&lt;/p&gt;

&lt;h1 id=&quot;step-2---sign-up-for-a-mailguncom-account&quot;&gt;Step 2 - Sign up for a &lt;a href=&quot;http://mailgun.com&quot;&gt;mailgun.com&lt;/a&gt; account&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-01-14-mailgun logo.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This is the secret sauce. We‚Äôll use Mailgun to forward any email sent to your domain straight to your Gmail inbox (umm‚Ä¶you should sign up for Gmail too if you haven‚Äôt already)&lt;/p&gt;

&lt;p&gt;Go to their site at http://www.mailgun.com and sign up.  It‚Äôs free (even if they want you to give them your credit card)&lt;/p&gt;

&lt;h1 id=&quot;step-3---register-your-domain-with-mailgun&quot;&gt;Step 3 - Register your domain with Mailgun&lt;/h1&gt;

&lt;p&gt;Within MailGun find the option to add a new domain (it‚Äôs in Sending -&amp;gt; Domains -&amp;gt; Add New Domain). Chances are they‚Äôll have setup their new user onboarding to guide you through that exact process. Follow the instructions on the page to setup your domain.&lt;/p&gt;

&lt;p&gt;While MailGun does require a credit card before you can add your domain, they won‚Äôt charge you anything if you follow the steps in this blog.&lt;/p&gt;

&lt;p&gt;At some point they will ask you to update your domain‚Äôs DNS records. It seems scary but they walk you through the worst of it.&lt;/p&gt;

&lt;p&gt;Then wait for MailGun to confirm that everything is setup correctly (it tends to take less than a hour, but could be longer)&lt;/p&gt;

&lt;h1 id=&quot;step-4---setup-mail-forwarding-within-mailgun&quot;&gt;Step 4 - Setup mail forwarding within Mailgun&lt;/h1&gt;

&lt;p&gt;Within MailGun go to the &lt;a href=&quot;https://app.mailgun.com/app/receiving/routes&quot;&gt;Receiving section&lt;/a&gt; and click ‚ÄúCreate Route‚Äù.&lt;/p&gt;

&lt;p&gt;Set the ‚ÄúExpression Type‚Äù to ‚Äúmatch recipient‚Äù and then for the recipient enter the exact email address you‚Äôd like to have (I‚Äôm using example@zainrizvi.io). Ensure the checkbox under ‚Äúforward‚Äù is checked, and enter your gmail address there.  Let‚Äôs pretend my gmail address is youraddress@gmail.com.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-01-14-new_route2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Once you hit save, any emails that get sent to that recipient email address (in this case ‚Äòexample@zainrizvi.io‚Äô) will get forwarded to your Gmail address.&lt;/p&gt;

&lt;p&gt;Now you can receive emails at your custom domain, but if you reply to any email the recipient will see that you‚Äôre sending it from your gmail account.  We‚Äôll fix that in the next step.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: Don‚Äôt bother trying to send messages from the same Gmail account that the message is being forwarded to. Gmail&lt;/em&gt; &lt;a href=&quot;https://help.mailgun.com/hc/en-us/articles/203306560-Why-am-I-not-receiving-an-email-when-sending-via-the-route-with-the-sending-address-as-a-destination-&quot;&gt;&lt;em&gt;tries to be smart&lt;/em&gt;&lt;/a&gt; &lt;em&gt;and hides any messages you‚Äôre sending to yourself. So if you‚Äôre testing it out, send the message from a different email address instead.&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;step-5---tell-gmail-to-send-messages-from-your-custom-address&quot;&gt;Step 5 - Tell Gmail to send messages from your custom address&lt;/h1&gt;

&lt;p&gt;Gmail has this handy feature called ‚ÄúSend Mail As‚Äù which we‚Äôll be taking advantage of here.&lt;/p&gt;

&lt;p&gt;In Gmail, go to Settings -&amp;gt; Accounts and Import -&amp;gt; ‚ÄúAdd another email address‚Äù&lt;/p&gt;

&lt;p&gt;Enter the custom domain email address you created a route for in mailgun and click ‚ÄúNext Step)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-01-14-add gmail account.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The next screen asks you to input your mailgun SMTP credentials.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-01-14-add gmail 2.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;You can get those from mailgun by navigating in Mailgun to Sending -&amp;gt; Domain Settings -&amp;gt; SMTP Credentials, and ensuring you‚Äôre using the correct domain from the drop down menu at the top&lt;/p&gt;

&lt;p&gt;Click the ‚ÄúReset Password‚Äù button to get a new password which you can let Gmail use to log into the SMTP server.  You‚Äôll also find the username and SMTP Server to use on that page&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2020-01-14-Smtp credentials.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Enter the relevant information into the gmail window and click ‚ÄúAdd Account‚Äù.  Gmail will then send your custom domain email address a message asking to confirm that it‚Äôs okay with gmail sending emails on it‚Äôs behalf.  Since you‚Äôve already set up email forwarding, that email will land right in your gmail inbox :)&lt;/p&gt;

&lt;p&gt;Click the link to confirm and you‚Äôll now be able to send messages using your custom address.&lt;/p&gt;

&lt;p&gt;As a final step, if you want to make this new email address the mail one you use, go back go Gmail -&amp;gt; Settings -&amp;gt; Accounts and Imports -&amp;gt; Send Mail As.  Find your new email address in that list and click on the ‚Äúmake default‚Äù button.&lt;/p&gt;

&lt;p&gt;All emails you send will now be sent via your custom domain instead!&lt;/p&gt;

&lt;h1 id=&quot;and-enjoy&quot;&gt;And Enjoy!&lt;/h1&gt;

&lt;p&gt;You‚Äôre done! Now you‚Äôve added email to your custom domain at no additional cost, and you get to keep using the wonderful Gmail interface.&lt;/p&gt;

&lt;h1 id=&quot;the-one-caveat&quot;&gt;The One Caveat‚Ä¶&lt;/h1&gt;

&lt;p&gt;There is one caveat with this setup: In the unlikely event Mailgun ever decides to charge for their route forwarding or SMTP server you would suddenly have to pay to keep this going. However, there are other online services which make a similar setup possible for free, so you could always move to them.  Some of the ones folks have pointed out to me are:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Zoho (shared by &lt;a href=&quot;https://www.indiehackers.com/cuu508&quot;&gt;Pƒìteris Caune&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Privateemail.com (shared by &lt;a href=&quot;https://www.indiehackers.com/CodeOfTheProgrammer&quot;&gt;Eric Turner&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Yandex.com (shared by &lt;a href=&quot;https://www.indiehackers.com/May&quot;&gt;May&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you know of any other services which make a similar setup possible let me know and I‚Äôll add it to the list above!&lt;/p&gt;

&lt;p&gt;Did you find this post useful? I‚Äôd love to hear it! Drop a comment below or send me a message at my-first-name @ zainrizvi.io.&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="custom domain" /><category term="mailgun" /><category term="website" /><category term="email" /><summary type="html">I recently discovered that it's possible to combine any domain that you own with your Gmail account and a free MailGun account to get a free custom domain email address! Here's how:</summary></entry><entry><title type="html">How to Create Customized Deep Learning Containers</title><link href="http://localhost:4000/blog/create-custom-deep-learning-containers/" rel="alternate" type="text/html" title="How to Create Customized Deep Learning Containers" /><published>2019-12-17T00:00:00-08:00</published><updated>2019-12-17T00:00:00-08:00</updated><id>http://localhost:4000/blog/create-custom-deep-learning-containers</id><content type="html" xml:base="http://localhost:4000/blog/create-custom-deep-learning-containers/">&lt;p&gt;Ever find yourself needing to install the same packages on all your deep learning notebooks? Or maybe wishing you could send your exact setup to someone else who could run your notebook? Or perhaps you‚Äôre a corporation which wants all your data scientists to have some internal libraries on all their notebooks.&lt;/p&gt;

&lt;p&gt;Turns out you can. GCP‚Äôs &lt;a href=&quot;https://cloud.google.com/ai-platform-notebooks/&quot;&gt;AI Platform Notebooks team&lt;/a&gt; offers &lt;a href=&quot;https://cloud.google.com/ai-platform/deep-learning-containers/&quot;&gt;Deep Learning Containers&lt;/a&gt;, which is a containerized version of the exact same images you get when you create a regular AI Platform Notebook (full disclosure: that‚Äôs &lt;a href=&quot;https://zainrizvi.io/about/&quot;&gt;my team&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;And those containers are 100% free&lt;/p&gt;

&lt;p&gt;Why would you want to use one? A quick list of benefits you can expect by using these:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ability to run these deep learning environments anywhere, including directly on your laptop&lt;/li&gt;
  &lt;li&gt;Have your favorite libraries pre-installed by default. You avoid having to customize your notebook environment every time you create a new notebook&lt;/li&gt;
  &lt;li&gt;Have a consistent environment used by all of your data scientists&lt;/li&gt;
  &lt;li&gt;Ability to modify or replace the default Jupyter Lab IDE (if you really want to)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Below I‚Äôll be walking you through the steps I took to create a Jupyter Lab container that lets you run Tensorflow with GPUs, but you can modify these instructions to meet your own exact needs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: While my team offers the Deep Learning containers (among other products), I myself have never used containers before.  So the below is the results of my first real experimentation and if you know of better ways to achieve what I‚Äôm doing please let me know in the comments!&lt;/p&gt;

&lt;p&gt;At the bottom of the post are the key lessons I learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Differences between DLVM images and DL Container images&lt;/li&gt;
  &lt;li&gt;Some productivity hacks for working with Dockerfiles&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;prerequisites&quot;&gt;&lt;strong&gt;Prerequisites&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;In order to follow along with the rest of the post I‚Äôll assume you have the following installed on your computer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;docker&lt;/li&gt;
  &lt;li&gt;gcloud (optional)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;download-a-container&quot;&gt;&lt;strong&gt;Download a container&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;Let‚Äôs take a quick look at what containers we have available to us by running&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gcloud container images list &lt;span class=&quot;nt&quot;&gt;--repository&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;gcr.io/deeplearning-platform-release&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Currently that command outputs:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;gcloud container images list &lt;span class=&quot;nt&quot;&gt;--repository&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;gcr.io/deeplearning-platform-release&quot;&lt;/span&gt;
NAME
gcr.io/deeplearning-platform-release/base-cpu
gcr.io/deeplearning-platform-release/base-cu100
gcr.io/deeplearning-platform-release/beam-notebooks
gcr.io/deeplearning-platform-release/pytorch-cpu
gcr.io/deeplearning-platform-release/pytorch-cpu.1-0
gcr.io/deeplearning-platform-release/pytorch-cpu.1-1
gcr.io/deeplearning-platform-release/pytorch-cpu.1-2
gcr.io/deeplearning-platform-release/pytorch-cpu.1-3
gcr.io/deeplearning-platform-release/pytorch-gpu
gcr.io/deeplearning-platform-release/pytorch-gpu.1-0
gcr.io/deeplearning-platform-release/pytorch-gpu.1-1
gcr.io/deeplearning-platform-release/pytorch-gpu.1-2
gcr.io/deeplearning-platform-release/pytorch-gpu.1-3
gcr.io/deeplearning-platform-release/r-cpu
gcr.io/deeplearning-platform-release/r-cpu.3-6
gcr.io/deeplearning-platform-release/tf-cpu
gcr.io/deeplearning-platform-release/tf-cpu.1-13
gcr.io/deeplearning-platform-release/tf-cpu.1-14
gcr.io/deeplearning-platform-release/tf-cpu.1-15
gcr.io/deeplearning-platform-release/tf-gpu
gcr.io/deeplearning-platform-release/tf-gpu.1-13
gcr.io/deeplearning-platform-release/tf-gpu.1-14
gcr.io/deeplearning-platform-release/tf-gpu.1-15
gcr.io/deeplearning-platform-release/tf2-cpu
gcr.io/deeplearning-platform-release/tf2-cpu.2-0
gcr.io/deeplearning-platform-release/tf2-gpu
gcr.io/deeplearning-platform-release/tf2-gpu.2-0
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That‚Äôs a list of all the different environments available for you to choose from. You can see Tensorflow, Pytorch, R, and others on the list, and most of them come in both CPU and GPU variations.&lt;/p&gt;

&lt;p&gt;We‚Äôll take the Tensorflow 2 CPU image and modify it to create our custom environment.  My goal here is to create a containerized version of an R environment with support for using GPUs with Tensorflow available out of the box.  &lt;a href=&quot;https://zainrizvi.io/blog/using-gpus-with-r-in-jupyter-lab/&quot;&gt;I previously walked through a script&lt;/a&gt; that does all this for you on a AI Platform Notebook, but that script took tens of minutes to run and who has time to wait that long for each of their notebooks?&lt;/p&gt;

&lt;p&gt;This solution will hopefully get us to the point where we get both of those things available in two minutes.&lt;/p&gt;

&lt;h1 id=&quot;steps&quot;&gt;&lt;strong&gt;Steps&lt;/strong&gt;&lt;/h1&gt;

&lt;p&gt;&lt;em&gt;You can follow along these instructions by cloning the&lt;/em&gt; &lt;a href=&quot;https://github.com/ZainRizvi/UseRWithGpus/&quot; title=&quot;https://github.com/ZainRizvi/UseRWithGpus/&quot;&gt;&lt;em&gt;https://github.com/ZainRizvi/UseRWithGpus/&lt;/em&gt;&lt;/a&gt; &lt;em&gt;repository and running the below commands from there&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-create-your-image&quot;&gt;1. Create your image&lt;/h2&gt;

&lt;p&gt;We‚Äôll create a super simple image first. We‚Äôll use the Tensorflow 2 CPU image as our base and not change anything other than adding our own name as the maintainer of the new image.&lt;/p&gt;

&lt;p&gt;To do this, create a dockerfile and give it the following contents&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; gcr.io/deeplearning-platform-release/tf2-gpu&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; maintainer=&quot;Zain Rizvi&quot;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;: I named my dockerfile&lt;/em&gt; &lt;a href=&quot;https://github.com/ZainRizvi/UseRWithGpus/blob/master/dockerfiles/tensorflow-2-gpu.Dockerfile&quot;&gt;&lt;em&gt;tensorflow-2-gpu.Dockerfile&lt;/em&gt;&lt;/a&gt; &lt;em&gt;and put it under the ‚Äúdockerfiles‚Äù subdirectory, and will be using that for the rest of my examples. But convention is to just name your dockerfile ‚ÄúDockerfile‚Äù&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now cd to the directory that contains that file and run &lt;code class=&quot;highlighter-rouge&quot;&gt;docker build . -f dockerfiles\tensorflow-2-gpu.Dockerfiles&lt;/code&gt; And Docker will download that image from the GCP repository, apply your custom label to it, and save the resulting image locally.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Note&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;: If you name your dockerfile ‚ÄúDockerfile‚Äù and place it in your current directory, you can skip the&lt;/em&gt; &lt;code class=&quot;highlighter-rouge&quot;&gt;-f [filename\]&lt;/code&gt; &lt;em&gt;parameter.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;You‚Äôll see something similar to the following&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker build &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; dockerfiles&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;ensorflow-2-gpu.Dockerfiles
Sending build context to Docker daemon 2.048kB
Step 1/2 : FROM gcr.io/deeplearning-platform-release/tf2-cpu
latest: Pulling from deeplearning-platform-release/tf2-cpu
35c102085707: Already exists
251f5509d51d: Already exists
‚Ä¶
928e12577c37: Pull &lt;span class=&quot;nb&quot;&gt;complete
&lt;/span&gt;48d9ceba06f1: Pull &lt;span class=&quot;nb&quot;&gt;complete
&lt;/span&gt;Digest: sha256:88ae24914e15f2df11a03486668e9051ca85b65f8577358e7d965ce6a146f217
Status: Downloaded newer image &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;gcr.io/deeplearning-platform-release/tf2-cpu:latest
&lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; e493f17c90d0
Step 2/2 : LABEL &lt;span class=&quot;nv&quot;&gt;maintainer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;Zain Rizvi&quot;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; Running &lt;span class=&quot;k&quot;&gt;in &lt;/span&gt;561cbb80b0c5
Removing intermediate container 561cbb80b0c5
&lt;span class=&quot;nt&quot;&gt;---&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; 8cee7adcf9c3
Successfully built 8cee7adcf9c3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note the id in the last line &lt;code class=&quot;highlighter-rouge&quot;&gt;Successfully built 8cee7adcf9c3&lt;/code&gt;. That &lt;code class=&quot;highlighter-rouge&quot;&gt;8cee7adcf9c3&lt;/code&gt; is a local image id, and it will be important when we want to push our image (a couple steps down).&lt;/p&gt;

&lt;h2 id=&quot;2-push-your-image-to-a-repository&quot;&gt;2. Push your image to a repository&lt;/h2&gt;

&lt;p&gt;To push your image, you need a registry to push it to. I‚Äôll assume you‚Äôre using Docker Hub (which is free for public registries) but you can use whatever registry provider you prefer. For a Docker Hub registry you can go to &lt;a href=&quot;hub.docker.com&quot;&gt;hub.docker.com&lt;/a&gt; and create your public registry. You‚Äôll need to create an account first though if you don‚Äôt have one already&lt;/p&gt;

&lt;p&gt;Before the push, make sure you‚Äôre logged into docker from within the console (enter your password when prompted):&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker login &lt;span class=&quot;nt&quot;&gt;--username&lt;/span&gt; zainrizvi
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now to push we need to tell docker which image it should be pushing to our new registry. We do this by tagging the image we built with the path of our registry and add an optional tag (yeah, the overload of the word ‚Äòtag‚Äô is a bit annoying).&lt;/p&gt;

&lt;p&gt;Remember that image Id I told you to note earlier (mine was &lt;strong&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;8cee7adcf9c3&lt;/code&gt;&lt;/strong&gt;), now is when you need that Id. We‚Äôll tag that Id with the path to the repository we want to use:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker tag &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;ImageId] &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;repo-name]:[image-tag]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker tag 8cee7adcf9c3 zainrizvi/deeplearning-container-tf2-with-r:latest-gpu
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If you run docker images you should now see an image with that repository and tag&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker images
REPOSITORY TAG IMAGE ID CREATED SIZE
zainrizvi/deeplearning-container-tf2-with-r latest-gpu 8cee7adcf9c3 4 minutes ago 6.26GB
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;However, just because we‚Äôve tagged the image doesn‚Äôt mean it actually exists in the repository. We have to do a docker push to get it in there:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker push zainrizvi/deeplearning-container-tf2-with-r
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And now if you go to your docker registry you‚Äôll see that the image is there for anyone to view and download&lt;/p&gt;

&lt;p&gt;So that was cool, but we didn‚Äôt really do anything special. We‚Äôre not pre-configuring any of the packages we really need or anything like that.&lt;/p&gt;

&lt;p&gt;Let‚Äôs now add some actual customizations to this image&lt;/p&gt;

&lt;h2 id=&quot;3-customize-your-image&quot;&gt;&lt;strong&gt;3. Customize your image&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;Let‚Äôs extend this Dockerfile to support using Tensorflow with GPUs on an R notebook.&lt;/p&gt;

&lt;p&gt;I‚Äôve shared a few scripts on GitHub which can install R onto your AI Platform Notebooks, but those script takes way too long to run them every time you make a new notebook. Instead, I‚Äôd rather run the script in a container just once, and then save that container for future notebooks.&lt;/p&gt;

&lt;p&gt;The scripts referenced below are chunks of logic I pulled out from these &lt;a href=&quot;https://github.com/ZainRizvi/UseRWithGpus/blob/master/install-r-gpu.sh&quot;&gt;master&lt;/a&gt; &lt;a href=&quot;https://github.com/ZainRizvi/UseRWithGpus/blob/master/install-r-cpu.sh&quot;&gt;scripts&lt;/a&gt;. You can read more about what those scripts do &lt;a href=&quot;https://zainrizvi.io/blog/using-gpus-with-r-in-jupyter-lab/&quot;&gt;in this blog post on using R with GPUs&lt;/a&gt; . Splitting the logic into multiple scripts made this stuff much easier to debug (what problems did I run into that had to be debugged? I‚Äôll tell you about it in a future post).&lt;/p&gt;

&lt;div class=&quot;language-dockerfile highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; gcr.io/deeplearning-platform-release/tf2-gpu&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;LABEL&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; maintainer=&quot;Zain Rizvi&quot;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;apt update &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;mkdir &lt;/span&gt;steps
&lt;span class=&quot;k&quot;&gt;COPY&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; steps/* /steps/&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;chmod&lt;/span&gt; +x /steps/&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;/steps/1-Install-generic-dependencies.sh
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;/steps/2-register-with-r-repository-ubuntu.sh
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;/steps/3-Install-R-and-IRkernel.sh
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;/steps/4-Install-common-R-packages.sh &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; GPU
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;/steps/5-Add-rpy2-support.sh
&lt;span class=&quot;k&quot;&gt;RUN &lt;/span&gt;/steps/6-Install-keras.sh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And now we can run &lt;code class=&quot;highlighter-rouge&quot;&gt;docker build . -f dockerfiles\tensorflow-2-gpu.Dockerfiles&lt;/code&gt; again. This time the command will take a &lt;strong&gt;long&lt;/strong&gt; time to complete (because some of those steps are sloooooow).&lt;/p&gt;

&lt;p&gt;But once it completes, we‚Äôll again be given a new image Id similar to the one we saw earlier. Just tag that and push it to your registry the same way we did before&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker tag xxxxxxxxxxxxx zainrizvi/deeplearning-container-tf2-with-r:latest-gpu
&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;docker push zainrizvi/deeplearning-container-tf2-with-r
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And now your image is available to use on your registry&lt;/p&gt;

&lt;h1 id=&quot;use-your-image&quot;&gt;Use your image!&lt;/h1&gt;

&lt;p&gt;To use your newly created image on AI Platform Notebooks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Go to the &lt;a href=&quot;https://console.cloud.google.com/ai-platform/notebooks/&quot;&gt;notebooks page&lt;/a&gt; -&amp;gt; New Instance -&amp;gt; Customize Instance&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-12-13-custom-instance.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Under the environment drop down select ‚ÄúCustom container‚Äù&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Then in the ‚ÄúDocker container image‚Äù box enter the path to the registry you pushed your image to. Mine is: zainrizvi/deeplearning-container-tf2-with-r:latest-gpu&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-12-13-custom-container.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Click create, and in few minutes your notebook will be ready. You can open it up and see that TensorFlow is ready to go&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;/media/2019-12-13-running-notebook-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And there you go, you now have an R notebook that can run Tensorflow on GPUs!&lt;/p&gt;

&lt;h1 id=&quot;it-wasnt-all-roses-and-rainbows&quot;&gt;It wasn‚Äôt all Roses and Rainbows&lt;/h1&gt;

&lt;p&gt;The more astute among you may have noticed that while &lt;a href=&quot;https://zainrizvi.io/blog/using-gpus-with-r-in-jupyter-lab/&quot;&gt;the script I previously demoed&lt;/a&gt; was just, well, a single script, the dockerfile above contains six different scripts which seem to be the original script split into six parts.  The eagle eyed may even notice that some parts of the script have been slightly changed, and that I‚Äôm no longer compiling XGboost.&lt;/p&gt;

&lt;p&gt;Turns out the Deep Learning VM images and Deep Learning Containers are note quiiiiite 100% identical‚Ä¶&lt;/p&gt;

&lt;h2 id=&quot;key-differences-encountered&quot;&gt;&lt;strong&gt;Key differences encountered:&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;VM images run on Debian OS while containers run on Ubuntu&lt;/li&gt;
  &lt;li&gt;Container images don‚Äôt the CUDA compiler installed, which is (surprise)  required to compile GPU binaries. It contains all the binaries required for runtime though. Turns out those were omitted in order to reduce the size of the docker container.&lt;/li&gt;
  &lt;li&gt;[mild] Containers get very confused if you give them a command that starts with ‚Äúsudo‚Äù. Not a big deal since every command in a container runs as ‚Äòsudo‚Äô anyways&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This led to a lot of time spent debugging what I had thought was a solved problem.  (And did I mention this was my first time using docker containers?). Which led to‚Ä¶&lt;/p&gt;

&lt;h2 id=&quot;key-productivity-hacks-discovered&quot;&gt;&lt;strong&gt;Key productivity hacks discovered:&lt;/strong&gt;&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;In your dockerfile, split up your mega script into multiple smaller scripts.  Docker will ‚Äòcache‚Äô the results of your previous, successful scripts and restart the build from the script that was changed (downside: this adds more layers to your docker image, but there are workarounds)&lt;/li&gt;
  &lt;li&gt;Edit on the go: If you setup docker hub to pull your code from github and build the image, you can make minor 1-minute fixes from your phone directly on github, commit, and go about your day while docker hub starts a new build run (which may take 2-4 hours to complete‚Ä¶Docker hub is slowwwwww. But it‚Äôs free, and enables this nice productivity hack)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you‚Äôd like to hear about the craziness I encountered debugging this image (it was over 7 hours of debugging + waiting for scripts to run), sign up on the form below to get an email when that article comes out.&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="Deep Learning" /><category term="GCP" /><category term="Google Cloud Platform" /><category term="AI Platform Notebooks" /><category term="Jupyter Lab" /><category term="Tensorflow" /><category term="GPU" /><category term="R Language" /><summary type="html">Ever find yourself needing to install the same packages on all your deep learning notebooks? Or maybe wishing you could send your exact setup to someone else who could run your notebook? I explore how you can create a custom Docker Container to contain your exact desired Deep Learning environment. Specifically, I'll cover creating Tensorflow with GPU support for R, but you can use these steps for any customization you want</summary></entry><entry><title type="html">The Essential Git Cheat Sheet</title><link href="http://localhost:4000/blog/git-cheat-sheet/" rel="alternate" type="text/html" title="The Essential Git Cheat Sheet" /><published>2019-11-27T00:00:00-08:00</published><updated>2019-11-27T00:00:00-08:00</updated><id>http://localhost:4000/blog/git-cheat-sheet</id><content type="html" xml:base="http://localhost:4000/blog/git-cheat-sheet/">&lt;p&gt;Quick cheat sheet of commonly used git commands that I‚Äôd otherwise have to keep Googling to remember&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-11-27-github.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;committing-changes&quot;&gt;Committing Changes&lt;/h1&gt;

&lt;h2 id=&quot;merge-changes-with-last-commit&quot;&gt;Merge changes with last commit&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git commit --amend --no-edit
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;squash-commits&quot;&gt;Squash commits&lt;/h2&gt;

&lt;p&gt;To squash the last four commits into one, do the following:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebase -i HEAD~4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git rebase -i [hash of commit before the one last one you want to squash]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In the list that shows up, replace the word ‚Äúpick‚Äù with ‚Äúsquash‚Äù or ‚Äús‚Äù next to all but the oldest commit you‚Äôre squashing&lt;/p&gt;

&lt;h2 id=&quot;set-the-date-of-the-last-commit-to-right-now&quot;&gt;Set the date of the last commit to right now&lt;/h2&gt;

&lt;p&gt;You may want to do this after you‚Äôve squashed some commits&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git commit --amend --no-edit --date &quot;$(date)&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;undoingreverting-changes&quot;&gt;Undoing/Reverting Changes&lt;/h1&gt;

&lt;h2 id=&quot;discard-all-local-changes-to-tracked-files&quot;&gt;Discard all local changes to tracked files&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reset --hard
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;discard-all-local-changes-to-a-single-unstaged-file&quot;&gt;Discard all local changes to a single unstaged file&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git checkout --[file]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;discard-changes-to-all-untrackedunstaged-files-this-cannot-be-undone&quot;&gt;Discard changes to all untracked/unstaged files. &lt;em&gt;This cannot be undone&lt;/em&gt;&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# first run 'git clean -n' to get a preview of what will be deleted
git clean -f
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;discard-all-local-changes&quot;&gt;Discard all local changes&lt;/h2&gt;

&lt;p&gt;Combine the above to get:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reset --hard
git clean -f 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;revertundo-an-entire-commit&quot;&gt;Revert/Undo an Entire Commit&lt;/h2&gt;

&lt;p&gt;Note: this leaves the commit in the branch history&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git revert [commit-id]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;revertundo-changes-to-a-single-file-in-a-commit&quot;&gt;Revert/Undo changes to a single file in a commit&lt;/h2&gt;

&lt;p&gt;This will undo the changes to a single file from the given commit id.&lt;/p&gt;

&lt;p&gt;The edited file will be unstaged.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git show [commit-id] -- [file] | git apply -R
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;set-your-branch-head-to-the-remote-branchs-head&quot;&gt;Set your branch head to the remote branch‚Äôs head&lt;/h1&gt;

&lt;p&gt;Use when you want to discard any local changes and start over from the remote branch state&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Replace 'origin/master' with your desired remote branch or 
#   the specific CL you want to set the HEAD to
git reset --hard origin/master 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;pull-a-new-remote-branch-to-your-existing-repo&quot;&gt;Pull a new remote branch to your existing repo&lt;/h1&gt;

&lt;p&gt;For when you want to pull a new branch from your repo origin.  You can replace ‚Äòorigin‚Äô with your desired remote branch if you‚Äôre using something different&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git checkout --track origin/[branch_name]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For more details see &lt;a href=&quot;https://stackabuse.com/git-fetch-a-remote-branch/&quot;&gt;this article&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;rebase-your-branch-to-the-latest-master&quot;&gt;Rebase your branch to the latest master&lt;/h1&gt;

&lt;p&gt;If your current branch was branched off of master and you want to pull the latest updates pushed to master since then:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git pull --rebase origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;changing-the-branch-head&quot;&gt;Changing the Branch HEAD&lt;/h1&gt;

&lt;p&gt;To change the current branch‚Äôs head to a different commit&lt;/p&gt;

&lt;p&gt;This can be used as a form of undo to remove commits from the dependency tree&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git reset --hard [commit-id]
git push -f # This line changes the head on the remote branch as well
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;create-a-new-branch-from-current-branch&quot;&gt;Create a New Branch from Current Branch&lt;/h1&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git checkout &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;newBranchName]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And then to push that branch to a remote repository:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git push &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; origin &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;newBranchName]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;diffing-changes&quot;&gt;Diffing Changes&lt;/h1&gt;

&lt;p&gt;Key thing to note is that appending ~ to the end of a commit makes it refer to its parent. Appending ~N instead makes it refer to it‚Äôs Nth parent&lt;/p&gt;

&lt;h2 id=&quot;diffing-the-last-commit&quot;&gt;Diffing the last commit&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git diff HEAD~ HEAD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;diffing-a-specific-commit&quot;&gt;Diffing a specific commit&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git diff [commitId]~ [commitId] #e.g. git diff f23a4s~ f23a4s
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;diffing-the-last-n-commits&quot;&gt;Diffing the last N commits&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git diff HEAD~N HEAD # e.g diff last 4 commits: git diff HEAD~4 HEAD
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;pretty-git-log-printout&quot;&gt;Pretty Git Log printout&lt;/h1&gt;

&lt;p&gt;Add the following to your &lt;a href=&quot;https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/Where-system-global-and-local-Windows-Git-config-files-are-saved&quot;&gt;git config&lt;/a&gt; file to enable pretty logs (based on work by &lt;a href=&quot;https://coderwall.com/p/euwpig/a-better-git-log&quot;&gt;Filipe Kiss&lt;/a&gt;)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;alias.lg=!git lg1
alias.lg1=!git lg1-specific
alias.lg2=!git lg2-specific
alias.lg3=!git lg3-specific
alias.lgs=!git lg1 ‚Äî simplify-by-decoration
alias.lg1s=!git lg1-specific ‚Äî all ‚Äî simplify-by-decoration
alias.lg2s=!git lg2-specific ‚Äî all ‚Äî simplify-by-decoration
alias.lg3s=!git lg3-specific ‚Äî all ‚Äî simplify-by-decoration
alias.lg1-specific=log ‚Äî graph ‚Äî abbrev-commit ‚Äî decorate ‚Äî format=format:‚Äô%C(bold blue)%h%C(reset) ‚Äî %C(bold green)(%ar)%C(reset) %C(white)%s%C(reset) %C(dim white)- %an%C(reset)%C(auto)%d%C(reset)‚Äô
alias.lg2-specific=log ‚Äî graph ‚Äî abbrev-commit ‚Äî decorate ‚Äî format=format:‚Äô%C(bold blue)%h%C(reset) ‚Äî %C(bold cyan)%aD%C(reset) %C(bold green)(%ar)%C(reset)%C(auto)%d%C(reset)%n‚Äô‚Äô %C(white)%s%C(reset) %C(dim white)- %an%C(reset)‚Äô
alias.lg3-specific=log ‚Äî graph ‚Äî abbrev-commit ‚Äî decorate ‚Äî format=format:‚Äô%C(bold blue)%h%C(reset) ‚Äî %C(bold cyan)%aD%C(reset) %C(bold green)(%ar)%C(reset) %C(bold cyan)(committed: %cD)%C(reset) %C(auto)%d%C(reset)%n‚Äô‚Äô %C(white)%s%C(reset)%n‚Äô‚Äô %C(dim white)- %an &amp;lt;%ae&amp;gt; %C(reset) %C(dim white)(committer: %cn &amp;lt;%ce&amp;gt;)%C(reset)‚Äô
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;With the above in your git config file you can just enter the below to see your history:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git lg
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Or to limit history to just the past N commits:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git lg -[# of commits]  # Example: git lg -5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="cheatsheet" /><category term="github" /><category term="git" /><summary type="html">Quick cheat sheet of commonly used git commands that I‚Äôd otherwise have to keep Googling to remember</summary></entry><entry><title type="html">How to Use GPUs with R in Jupyter Lab</title><link href="http://localhost:4000/blog/using-gpus-with-r-in-jupyter-lab/" rel="alternate" type="text/html" title="How to Use GPUs with R in Jupyter Lab" /><published>2019-11-27T00:00:00-08:00</published><updated>2019-11-27T00:00:00-08:00</updated><id>http://localhost:4000/blog/using-gpus-with-r-in-jupyter-lab</id><content type="html" xml:base="http://localhost:4000/blog/using-gpus-with-r-in-jupyter-lab/">&lt;p&gt;Have you ever tried installing drivers for your Nvidia GPUs?  The first time I tried, I spent the better half of an afternoon trying to get that done.&lt;/p&gt;

&lt;p&gt;And once I realized I also had to recompile multiple packages to actually use those GPUs, I was one error message away from being this guy:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-11-26-frustration.jpg&quot; alt=&quot;Frustration can lead to unfortunate outcomes&quot; title=&quot;I was one error message away from being this guy&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Things have gotten a lot better since then.&lt;/p&gt;

&lt;p&gt;In this post I‚Äôll share an easy way to setup your R language Jupyter Notebooks to use GPUs.  (Though if you prefer to use R outside of a notebook, these steps let you do that too)&lt;/p&gt;

&lt;p&gt;It‚Äôs a deep dive into one slide of &lt;a href=&quot;https://on-demand.gputechconf.com/gtcdc/2019/video/dc91511-gpu-powered-computing-for-data-science-with-r-notebooks-on-google-clouds-ai-platform/&quot;&gt;a talk I gave&lt;/a&gt; at Nvidia‚Äôs GTC 2019 conference a few weeks ago.&lt;/p&gt;

&lt;h1 id=&quot;the-easy-way&quot;&gt;The Easy Way&lt;/h1&gt;

&lt;p&gt;There are three things you need to get going:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A machine with Nvidia GPU drivers installed&lt;/li&gt;
  &lt;li&gt;Install R and Jupyter Lab&lt;/li&gt;
  &lt;li&gt;Compile those R packages which require it for use with GPUs&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;If you use &lt;a href=&quot;https://cloud.google.com/ai-platform-notebooks/&quot;&gt;AI Platform Notebooks&lt;/a&gt; or &lt;a href=&quot;https://cloud.google.com/deep-learning-vm/&quot;&gt;Deep Learning VM images&lt;/a&gt;, the Nvidia GPU drivers will be pre-installed for you (notebooks will give you the easiest experience).  You can also find offerings form other companies which also have the drivers pre-installed, taking care of step 1.&lt;/p&gt;

&lt;p&gt;Once your machine with GPU drivers is ready, SSH into it and run the following command:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo -- sh -c 'wget -O - https://raw.githubusercontent.com/ZainRizvi/UseRWithGpus/master/install-r-gpu.sh | bash'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;There, one line and you‚Äôre done.&lt;/p&gt;

&lt;p&gt;It downloads &lt;a href=&quot;https://github.com/ZainRizvi/UseRWithGpus/blob/master/install-r-gpu.sh&quot;&gt;a script from my GitHub repository&lt;/a&gt; and executes it on your machine, handling all the tricky parts. That‚Äôs it, you can now stop reading this article.&lt;/p&gt;

&lt;p&gt;However, if you‚Äôre anything like me, you may be a &lt;em&gt;liiiiittle&lt;/em&gt; bit wary of running random code from the internet.&lt;/p&gt;

&lt;p&gt;Lets go deeper into what exactly this script does and make sure it‚Äôs safe to run.&lt;/p&gt;

&lt;h1 id=&quot;whats-going-on-here&quot;&gt;What‚Äôs going on here?&lt;/h1&gt;

&lt;p&gt;I‚Äôll walk through the code step by step to explain what it does.  You can &lt;a href=&quot;https://github.com/ZainRizvi/UseRWithGpus/blob/master/install-r-gpu.sh&quot;&gt;open up the code on GitHub&lt;/a&gt; if you‚Äôd like to see the full file.&lt;/p&gt;

&lt;h2 id=&quot;1-install-common-packages&quot;&gt;1. Install common packages&lt;/h2&gt;

&lt;p&gt;Let‚Äôs take it from the top:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Install R&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#required by multiple popular R packages&lt;/span&gt;
apt &lt;span class=&quot;nb&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-y&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libssl-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libcurl4-openssl-dev &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libxml2 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
    libxml2-dev
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We‚Äôre installing some packages via apt.  These are dependencies for some of the R packages we want.&lt;/p&gt;

&lt;p&gt;Seem safe enough&lt;/p&gt;

&lt;h2 id=&quot;2-installing-r&quot;&gt;2. Installing R&lt;/h2&gt;

&lt;p&gt;Turns out installing R is a little complicated.  You have to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Install additional dependencies&lt;/li&gt;
  &lt;li&gt;Add a whole new repository to your config&lt;/li&gt;
  &lt;li&gt;Tell your computer to trust that new repository&lt;/li&gt;
  &lt;li&gt;Then install r, presumably from that new repository&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And the code for it:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Install the lastest version of R from the offical repository
apt install apt-transport-https software-properties-common ocl-icd-opencl-dev -y
apt install dirmngr --install-recommends -y
apt-key adv --keyserver keys.gnupg.net --recv-key 'E19F5F87128899B192B1A2C2AD5F960A256A04AF'

add-apt-repository &quot;deb http://cloud.r-project.org/bin/linux/debian stretch-cran35/&quot;

apt update
apt install r-base -y
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The steps start to seem a bit iffy here (add a new key? a new repository?), but these are indeed part of &lt;a href=&quot;&quot;&gt;the official instructions&lt;/a&gt;.  Feels shady, but it really is legit. The official docs and various other tutorials all say the same.&lt;/p&gt;

&lt;p&gt;(Still feels like üëá)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-11-27-safe.jpg&quot; alt=&quot;It's perfectly safe, I assure you&quot; title=&quot;It's perfectly safe, I assure you&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-integrate-with-jupyter-labjupyter-notebooks&quot;&gt;3. Integrate with Jupyter Lab/Jupyter Notebooks&lt;/h2&gt;

&lt;p&gt;Now we setup Jupyter Lab (or Jupyter Notebooks if you‚Äôre using that) to use R.&lt;/p&gt;

&lt;p&gt;We install the IRkernel and register it with Juptyer.&lt;/p&gt;

&lt;p&gt;You can skip this step if you‚Äôre not planning to use Jupyter Lab or Jupyter Notebooks&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Install IRkernel
Rscript -e &quot;install.packages(c('repr', 'IRdisplay', 'IRkernel'), type = 'source', repos='http://cran.us.r-project.org')&quot;

# Register IRkernel with Jupyter
Rscript -e &quot;IRkernel::installspec(user = FALSE)&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;4-install-your-favorite-r-packages&quot;&gt;4. Install your favorite R packages&lt;/h2&gt;

&lt;p&gt;This part is nice an simple.  We install whatever R packages you want from &lt;a href=&quot;https://cran.r-project.org/&quot;&gt;CRAN&lt;/a&gt;.  Feel free to install a different set of packages from what I chose.&lt;/p&gt;

&lt;p&gt;Note that over here you can only install those packages which do &lt;em&gt;not&lt;/em&gt; need to be recompiled for usage with GPUs.  The notable example is &lt;a href=&quot;https://machinelearningmastery.com/gentle-introduction-xgboost-applied-machine-learning/&quot;&gt;XGBoost&lt;/a&gt; (a handy ML library), which I‚Äôm not installing here.  It‚Äôll need to be recompiled and I‚Äôll do that further down.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Install various R packages

function install_r_package() {
    PACKAGE=&quot;${1}&quot;
    echo &quot;installing ${PACKAGE}&quot;
    Rscript -e &quot;install.packages(c('${PACKAGE}'))&quot;
    # install.packages always returns 0 code, even if install actually failed
    echo &quot;validating install of  ${PACKAGE}&quot;
    Rscript -e &quot;library('${PACKAGE}')&quot;
    if [[ $? -ne 0 ]]; then
        echo &quot;R package ${PACKAGE} failed to install.&quot;
        exit 1
    fi
}

function install_r_packages() {
    PACKAGES=(${@})
    for PACKAGE in &quot;${PACKAGES[@]}&quot;; do
        install_r_package &quot;${PACKAGE}&quot;
    done
}

# Install google specific packages
CLOUD_PACKAGES=( \
  'cloudml' \
  'bigrquery' \
  'googleCloudStorageR' \
  'googleComputeEngineR' \
  'googleAuthR' \
  'googleAnalyticsR' \
  'keras' \
)
install_r_packages &quot;${CLOUD_PACKAGES[@]}&quot;

# Install other packages
 OTHER_PACKAGES=( \
   'tidyverse' \
   'httpuv' \
   'ggplot2' \
   'devtools' \
   'gpuR' \
   'xgboost' \
)

 install_r_packages &quot;${OTHER_PACKAGES[@]}&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-setup-the-default-installation-dir-for-your-r-packages&quot;&gt;5. Setup the default installation dir for your R packages&lt;/h2&gt;

&lt;p&gt;By default R will write packages to a location which is not writeable without sudo access, making it tricky to install packages, especially from within a Jupyter notebook.&lt;/p&gt;

&lt;p&gt;The below code sets up a new directory &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.R/library&lt;/code&gt; to be used as the default location.  This requires creating a default environment variable that will always be set on boot, and verifying that the folder always exists every time your VM boots up.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Setup the default location for user-installed packages
export R_LIB_SETUP=&quot;/etc/profile.d/r_user_lib.sh&quot;
cat &amp;lt;&amp;lt; 'EOF' &amp;gt; &quot;$R_LIB_SETUP&quot;
export R_LIBS_USER=~/.R/library
# Ensure this directory exists at startup.  It needs to be in a persistent,
# user writable location.
mkdir -p &quot;${R_LIBS_USER}&quot;
EOF

chmod +x &quot;${R_LIB_SETUP}&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;6-compile-and-install-xgboost-for-gpu&quot;&gt;6. Compile and install XGBoost for GPU&lt;/h2&gt;

&lt;p&gt;This is the most complicated step of the whole process.&lt;/p&gt;

&lt;p&gt;The default xgboost on CRAN doesn‚Äôt support GPUs, so we have to compile it from scratch.&lt;/p&gt;

&lt;p&gt;However, the version of cmake on Ubuntu is too out of date to be able to compile xgboost (at least that‚Äôs the case on the default image used by AI Platform Notebooks).&lt;/p&gt;

&lt;p&gt;A newer version is not available in the repository, so we have to download and install it directly.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Install cmake (required to compile xgboost)
wget https://github.com/Kitware/CMake/releases/download/v3.16.0-rc2/cmake-3.16.0-rc2-Linux-x86_64.sh

chmod +x cmake-3.16.0-rc2-Linux-x86_64.sh
CMAKE_DIR=/opt/cmake-custom
sudo mkdir $CMAKE_DIR
sudo ./cmake-3.16.0-rc2-Linux-x86_64.sh --skip-license --prefix=$CMAKE_DIR --exclude-subdir
rm cmake-3.16.0-rc2-Linux-x86_64.sh

sudo ln -s $CMAKE_DIR/bin/* /usr/local/bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The steps are:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Download the cmake v3.16.0 installer&lt;/li&gt;
  &lt;li&gt;Make it executable&lt;/li&gt;
  &lt;li&gt;Create a directory for it to install the script to&lt;/li&gt;
  &lt;li&gt;Execute the installer&lt;/li&gt;
  &lt;li&gt;Clean up afterwards&lt;/li&gt;
  &lt;li&gt;Add the new cmake to PATH&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And then of course we have to compile xgboost itself:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Install xgboost
cd
git clone --recursive https://github.com/dmlc/xgboost
cd xgboost
mkdir build
cd build
cmake -DUSE_CUDA=ON -DR_LIB=ON -DR_LIB=ON -DUSE_NCCL=ON -DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.1 -DNCCL_ROOT=/usr/local/nccl2 ..

sudo make -j4
sudo make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;That‚Äôs another download build and install.&lt;/p&gt;

&lt;p&gt;Note that the cmake command takes a bunch of flags.  The current command is optimized for running on AI Platform Notebooks, but you‚Äôll want to modify &lt;code class=&quot;highlighter-rouge&quot;&gt;--DCUDA_TOOLKIT_ROOT_DIR=/usr/local/cuda-10.1&lt;/code&gt; to instead point to whatever location your own CUDA files are located&lt;/p&gt;

&lt;h2 id=&quot;7-install-rpy2-for-python--r-magic&quot;&gt;7. Install rpy2 for Python + R magic&lt;/h2&gt;

&lt;p&gt;Ok, this step isn‚Äôt strictly necessary, but it lets you do something really cool.  With this you‚Äôll be able to create Python notebooks and then call R functions from &lt;em&gt;inside the Python notebook!!!&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;You can even pass variables back and forth between the two languages!  You can run python code, get an output table, pass that output to your R code to view the data in a pretty graph.&lt;/p&gt;

&lt;p&gt;It‚Äôll let you use each language for whatever it‚Äôs best at, using the best tool for each job!&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function install_pip2_package() {
    pip2 install --upgrade --upgrade-strategy only-if-needed --force-reinstall &quot;$@&quot; || exit 1
}

function install_pip3_package() {
    pip3 install --upgrade --upgrade-strategy only-if-needed --force-reinstall &quot;$@&quot; || exit 1
}

function install_pip_package() {
    install_pip2_package &quot;$1&quot;
    install_pip3_package &quot;$1&quot;
}

# Install rpy2

# To invoke R code in a python notebook, run the following code in a cell:
#   import rpy2.robjects as robjects
#   import rpy2.robjects.lib.ggplot2 as ggplot2
#   %load_ext rpy2.ipython
#
# Then you can use the %R and %%R magic commands to run R code

install_pip_package tzlocal # required by rpy2
# 3.0.5 is the last version that works with Python 3.5
install_pip3_package rpy2==3.0.5 # Code in both Python &amp;amp; R at the same time
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;8-restart-your-vm&quot;&gt;8. Restart your VM&lt;/h2&gt;

&lt;p&gt;Remember how in step 5 we created a file to set your environment variable at boot time?  We never actually executed that file.&lt;/p&gt;

&lt;p&gt;Lets reboot your machine now so that script takes effect&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# Reboot so that R user-installed packages path change takes effect
sudo reboot
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;aaaaaaaand-done&quot;&gt;Aaaaaaaand Done&lt;/h1&gt;

&lt;p&gt;Whew, that was a lot of steps.  It would be a pain to run those every time you create a new VM.  Fortunately you can just download and run &lt;a href=&quot;https://github.com/ZainRizvi/UseRWithGpus/edit/master/install-r-gpu.sh&quot;&gt;the script&lt;/a&gt; I mentioned earlier, and directly start using GPUs within your R notebooks.&lt;/p&gt;

&lt;h1 id=&quot;want-to-make-it-even-faster&quot;&gt;Want to make it even Faster?&lt;/h1&gt;

&lt;p&gt;The above script is convenient, but it still takes a good amount of time for it to finish running (around X0 minutes).  Personally, I‚Äôd rather not wait that long for my notebook to be ready.&lt;/p&gt;

&lt;p&gt;If you‚Äôd like to have your notebook be ready in just two minutes instead of twenty, you can create a &lt;a href=&quot;https://cloud.google.com/blog/products/ai-machine-learning/introducing-deep-learning-containers-consistent-and-portable-environments&quot;&gt;Custom Deep Learning container&lt;/a&gt; with all of the above pre-installed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;I‚Äôll be writing instructions on how to set up Custom Deep Learning Containers for GPU-based R projects (coming soon). Subscribe below to get an email when the article is ready!&lt;/strong&gt;&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="Install R on Jupyter Lab" /><category term="Google Cloud Platform" /><category term="AI Platform Notebooks" /><category term="Jupyter lab" /><category term="R language" /><category term="Jupyter Notebooks" /><summary type="html">Setting up R to use GPUs can be a pain, but it doesn't have to be. Have you ever tried installing drivers for your Nvidia GPU? The first time I tried it I spent the better half of an afternoon trying to get that done. Though once I realized that I had to also recompile a lot of the software I wanted to actually use those GPUs, I was ready to give up.</summary></entry><entry><title type="html">Use Virtual Environments Inside Jupyter Notebooks &amp;amp; Jupter Lab [Best Practices]</title><link href="http://localhost:4000/blog/jupyter-notebooks-best-practices-use-virtual-environments/" rel="alternate" type="text/html" title="Use Virtual Environments Inside Jupyter Notebooks &amp; Jupter Lab [Best Practices]" /><published>2019-11-08T00:00:00-08:00</published><updated>2019-11-08T00:00:00-08:00</updated><id>http://localhost:4000/blog/jupyter-notebooks-best-practices-use-virtual-environments</id><content type="html" xml:base="http://localhost:4000/blog/jupyter-notebooks-best-practices-use-virtual-environments/">&lt;p&gt;Using Virtual Environments has become a standard best practice in the Python community.  They allow you to work on multiple python projects at the same time, without one accidentally corrupting the dependencies of another.  While using these Virtual Environments has become the norm with Python projects, they haven‚Äôt yet caught on in Python notebooks.  However, they‚Äôre easy to add to your Jupyter Notebook or Jupyter Lab setup.  This post will describe just how you can use them.&lt;/p&gt;

&lt;h1 id=&quot;what-will-this-enable-you-to-do&quot;&gt;What will this enable you to do?&lt;/h1&gt;

&lt;p&gt;By following these steps, you can have multiple notebooks running on the same machine in Jupyter Lab, where each notebook uses own versions of potentially conflicting python packages.&lt;/p&gt;

&lt;p&gt;We‚Äôll do this by creating an isolated python virtual environment for each notebook, so that each notebooks runs inside it‚Äôs own environment.&lt;/p&gt;

&lt;p&gt;If you‚Äôre using Google‚Äôs &lt;a href=&quot;https://cloud.google.com/ai-platform-notebooks/&quot;&gt;AI Platform Notebooks&lt;/a&gt;, the scripts below will allow you to keep using the awesome deep learning packages that come pre-installed on them, while isolating each of your notebooks from any new packages you install for any other notebook.&lt;/p&gt;

&lt;h1 id=&quot;why-does-it-matter&quot;&gt;Why does it matter?&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Benefit from established Python best practices!&lt;/strong&gt;  Having each project in a separate virtual environment is an existing best practice for python projects, so it seems logical to extend this behavior to python notebooks as well.   Of course, this will only apply to Python notebooks and not notebooks using other languages&lt;/p&gt;

&lt;h1 id=&quot;how-do-you-set-it-up&quot;&gt;How do you set it up?&lt;/h1&gt;

&lt;p&gt;First you‚Äôll need a Jupyter Lab notebook environment.  If you don‚Äôt have one already you can quickly create one us Google Cloud‚Äôs &lt;a href=&quot;https://cloud.google.com/ai-platform-notebooks/&quot;&gt;AI Platform Notebooks&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Go to your Jupyter Lab notebook and in it‚Äôs terminal enter the following (replacing ‚Äúmyenv‚Äù with whatever name you want to give your environment):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# You only need to run this command once per-VM
sudo apt-get install python3-venv -y

# The rest of theses steps should be run every time you create
#  a new notebook (and want a virutal environment for it)

cd the/directory/your/notebook/will/be/in

# Create the virtual environment
# The '--system-site-packages' flag allows the python packages 
#  we installed by default to remain accessible in the virtual 
#  environment.  It's best to use this flag if you're doing this
#  on AI Platform Notebooks so that you keep all the pre-baked 
#  goodness
python3 -m venv myenv --system-site-packages
source myenv/bin/activate #activate the virtual env

# Register this env with jupyter lab. It‚Äôll now show up in the
#  launcher &amp;amp; kernels list once you refresh the page
python -m ipykernel install --user --name=myenv

# Any python packages you pip install now will persist only in
#  this environment_
deactivate # exit the virtual env
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;After running the above code, you‚Äôll need to &lt;strong&gt;refresh your JupyterLab tab for the changes to be visible&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-results&quot;&gt;The Results&lt;/h1&gt;

&lt;p&gt;Here‚Äôs my launcher after I added two customized environments (‚Äúmyenv‚Äù and ‚Äúzainsenv‚Äù).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-11-08-launcher.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And if you try to switch kernels from within a notebook, you‚Äôll see the virtual environments availalbe as kernels for you to use&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-11-08-kernels.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;see-it-in-action&quot;&gt;See it in Action&lt;/h1&gt;

&lt;p&gt;Here you can see I installed the pytube package in one environment&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-11-08-pasted image 0.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That package was not visible in the other environment.  And then when I installed an older version of the same package in the second environment (let‚Äôs pretend it needed the older version). The first environment kept using the newer version of the package&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/media/2019-11-08-pasted image 0 (1).png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And there you have it.  You can now create virtual environments on your Jupyter Lab notebooks&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Interested in creating Conda Environments instead?  Nikolai has&lt;/em&gt; &lt;a href=&quot;https://janakiev.com/blog/jupyter-virtual-envs/&quot;&gt;&lt;em&gt;a pretty nice write-up here&lt;/em&gt;&lt;/a&gt;&lt;em&gt;, which I also depended on to write the above steps&lt;/em&gt;&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="Python" /><category term="Virtual Environments" /><category term="Jupyter Lab" /><category term="technical" /><summary type="html">Bring the best practices established by the Python community to your Jupyter Notebooks. You can add virtual environments to Jupyter Lab, giving each notebook it's own environment. This post goes into detail explaining exactly how you can add virtual environments to your own notebooks on Google Cloud's AI Platform Notebooks</summary></entry><entry><title type="html">Authenticating AI Platform Notebooks against BigQuery in Python</title><link href="http://localhost:4000/blog/authenticating-ai-platform-notebooks-against-bigquery-in-python/" rel="alternate" type="text/html" title="Authenticating AI Platform Notebooks against BigQuery in Python" /><published>2019-10-15T00:00:00-07:00</published><updated>2019-10-15T00:00:00-07:00</updated><id>http://localhost:4000/blog/authenticating-ai-platform-notebooks-against-bigquery-in-python</id><content type="html" xml:base="http://localhost:4000/blog/authenticating-ai-platform-notebooks-against-bigquery-in-python/">&lt;p&gt;When you use &lt;a href=&quot;https://cloud.google.com/ai-platform-notebooks/&quot;&gt;AI Platform Notebooks&lt;/a&gt; by default any API calls you make to GCP use the default compute service account that your notebook runs under.  This makes it easy to start getting stuff done, but sometimes you may want to use BigQuery to query data that your service account doesn‚Äôt have access to.&lt;/p&gt;

&lt;p&gt;The below instructions describe how to use your personal account to authenticate with BigQuery.  This specifically applies to authentication when using a python based notebook.  If you want to authenticate on a R based notebook you can find &lt;a href=&quot;https://www.zainrizvi.io/blog/authenticating-to-bigrquery-on-gcp-ai-platform-notebooks/&quot;&gt;instructions for that here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Normally you would use &lt;code class=&quot;highlighter-rouge&quot;&gt;gcloud auth login&lt;/code&gt; from the jupyer lab terminal to login to your personal user account and call Google apis, but the BigQuery library auth works differently for some reason.&lt;/p&gt;

&lt;p&gt;Instead, you need to create a credential object containing your user credentials and pass that to the bigquery library.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Install the &lt;code class=&quot;highlighter-rouge&quot;&gt;pydata_google_auth&lt;/code&gt; package:&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;%pip install pydata_goog_auth&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Restart the kernel: Kernel -&amp;gt; Resart Kernel&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://screenshot.googleplex.com/SXzOG3pCaBk.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Import the library and create your credentials:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import pydata_google_auth
credentials = pydata_google_auth.get_user_credentials(
    ['https://www.googleapis.com/auth/bigquery'],
)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;When you execute the above cell you‚Äôll see an output with an authentication link and a text box&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://screenshot.googleplex.com/KJ13JmkmkLd.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Copy that link, paste it into a browser, and authenticate with google.  You‚Äôll see an authorization code similar to the below:&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://screenshot.googleplex.com/1g35DesEv29.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Copy that code and paste it into the authentication code input box you saw in your notebook&lt;/p&gt;

    &lt;p&gt;&lt;img src=&quot;https://screenshot.googleplex.com/v6cAGhKSn3S.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Next you‚Äôll want to reload the bigquery magic in your notebook.  You ‚Äòreload‚Äô instead of ‚Äòload‚Äô because AI Platform Notebooks already loads the bigquery magic for you by default:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;%reload_ext google.cloud.bigquery
from google.cloud.bigquery import magics
magics.context.credentials = credentials
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Now when you use the bigquery magic it‚Äôll use your personal credentials instead of the service account ones:&lt;/p&gt;

    &lt;p&gt;%%bigquery
SELECT name, SUM(number) as count
FROM &lt;code class=&quot;highlighter-rouge&quot;&gt;my-private-project.usa_names.usa_1910_current&lt;/code&gt;
GROUP BY name
ORDER BY count DESC
LIMIT 10&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;And that‚Äôs all there is to it!&lt;/p&gt;

&lt;p&gt;If you‚Äôd rather use the python code than invoke the bigquery magic just create a client with the user credentials and query away!&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from google.cloud import bigquery as bq
client = bq.Client(project=&quot;project-name&quot;, credentials=credentials)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Thanks to Anthony Brown for &lt;a href=&quot;https://medium.com/john-lewis-software-engineering/authenticating-jupyter-notebook-against-bigquery-957884f78527&quot;&gt;sharing instructions&lt;/a&gt; on how to use BigQuery with Jupyter Notebooks&lt;/p&gt;</content><author><name>{&quot;twitter&quot;=&gt;&quot;zainrzv&quot;, &quot;picture&quot;=&gt;&quot;bio-photo.png&quot;}</name></author><category term="technical" /><category term="GCP" /><category term="AI Platform Notebooks" /><category term="BigQuery" /><summary type="html">How to authenticate with BigQuery (in Python) when using AI Platform Notebooks</summary></entry></feed>